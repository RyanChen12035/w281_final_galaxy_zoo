{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%pip install thundersvm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp310-cp310-win_amd64.whl (2704.2 MB)\n",
            "     ---------------------------------------- 2.7/2.7 GB 783.0 kB/s eta 0:00:00\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp310-cp310-win_amd64.whl (4.9 MB)\n",
            "     ---------------------------------------- 4.9/4.9 MB 24.1 MB/s eta 0:00:00\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp310-cp310-win_amd64.whl (4.0 MB)\n",
            "     ---------------------------------------- 4.0/4.0 MB 14.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.8.0)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "     ---------------------------------------- 5.7/5.7 MB 21.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: networkx in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.12.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\immanueldesktop\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
            "Collecting mpmath>=0.19 (from sympy->torch)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "     ------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio\n",
            "Successfully installed mpmath-1.3.0 sympy-1.12 torch-2.2.2+cu118 torchaudio-2.2.2+cu118 torchvision-0.17.2+cu118\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFmXi1Tp178m",
        "outputId": "3b9eb2a8-b0a4-43ba-9a11-cd7691dfbf10"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Adopt reduced data set (2000 examples, 500 for each category),\n",
        "Get features from pipeline1, 2, 3 and pass it LDA and SVN. Do the grid search.\n",
        "- pipeline1 (Canny + SIFT):\n",
        "\tpreprocess: grayscale, histogram_clipping, gaussian_blur_preprocessing, bilateral_preprocessing, sobel_preprocessing, canny_filter, center_crop\n",
        "\tfeature extractor: sift_bag_of_visual_words (200 features)\n",
        "\tfeature reduction: no PCA needed, normalized feature-wise by dividing maximum\n",
        "\tclassifier LDA + linear regression: train_accuracy: 0.63 , val_accuracy: 0.45\n",
        "\tclassifier SVM (non-linae, 'rbf'): train_accuracy: 0.71 , val_accuracy: 0.51\n",
        "\targuments for grid search: number of PCA features, C of SVM, C of linear regression\n",
        "- pipeline2 (HOG):\n",
        "\tpreprocess: grayscale, histogram_clipping, gaussian_blur_preprocessing, bilateral_preprocessing, center_crop\n",
        "\tfeature extractor: hog feature (63504 features)\n",
        "\tfeature reduction: PCA, from 63504 down to 200 features, z score normalization needed.\n",
        "\tclassifier LDA + linear regression: train_accuracy: 0.8 , val_accuracy: 0.65 (L1 regularization)\n",
        "\tclassifier SVM (non-linae, 'rbf'): train_accuracy: 0.95, val_accuracy: 0.64\n",
        "\targuments for grid search: number of PCA features, C of SVM, C of linear regression and L regularization\n",
        "- pipeline3 (Resnet50):\n",
        "\tpreprocess: N/A\n",
        "\tfeature extractor: body of resnet50 (detach classifer head) (2048 features)\n",
        "\tfeature reduction: PCA, from 2048 down to 100 features, no normalization needed.\n",
        "\tclassifier LDA + linear regression: train_accuracy: 0.28 , val_accuracy: 0.05 (L1 regularization)\n",
        "\tclassifier SVM (non-linae, 'rbf'): train_accuracy: 0.89 , val_accuracy: 0.41\n",
        "\targuments for grid search: number of PCA features, C of SVM, C of linear regression and L1 regularization\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "# mount Google Drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7RQTcPXD8Uiy"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "# copy the filters from ex7\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from PIL import Image\n",
        "import urllib\n",
        "from skimage import feature, io, color\n",
        "from scipy.cluster.vq import kmeans\n",
        "\n",
        "np.random.seed(62)\n",
        "from scipy.cluster.vq import vq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data imports\n",
        "If using local: use the second code block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TLnQAxM8b9o",
        "outputId": "b143b673-7532-4c1e-9055-d6af882f5261"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "import pandas as pd\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/galaxy_zoo/train_data_reduced.csv\"\n",
        "column_names = [\"path\", \"index\", \"label\"]\n",
        "df_train = pd.read_csv(csv_file_path, names=column_names)\n",
        "df_train = df_train.iloc[1:]\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "print(df_train.shape)\n",
        "# val data\n",
        "import pandas as pd\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/galaxy_zoo/val_data_reduced.csv\"\n",
        "column_names = [\"path\", \"index\", \"label\"]\n",
        "df_val = pd.read_csv(csv_file_path, names=column_names)\n",
        "df_val = df_val.iloc[1:]\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "print(df_val.shape)\n",
        "# test data\n",
        "csv_file_path = \"/content/drive/MyDrive/galaxy_zoo/test_data_reduced.csv\"\n",
        "column_names = [\"path\", \"index\", \"label\"]\n",
        "df_test = pd.read_csv(csv_file_path, names=column_names)\n",
        "df_test = df_test.iloc[1:]\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(csv_file_path):\n",
        "    \"\"\"\n",
        "    Read data and remove file paths that are duplicates\n",
        "    \"\"\"\n",
        "    # csv_file_path = \"./\"\n",
        "    column_names = [\"path\", \"index\", \"label\"]\n",
        "    df = pd.read_csv(csv_file_path, names=column_names)\n",
        "    df[\"path\"] = df[\"path\"].map(\n",
        "        lambda x: \"Train_images/Train_images/\" + \"/\".join(x.split(\"/\")[-2:])\n",
        "    )\n",
        "    df = df[~df[\"path\"].str.contains(\"(1)\", regex=False)]\n",
        "    df = df.iloc[1:]\n",
        "    df = df.reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "df_train = read_data(\"train_data.csv\")\n",
        "df_test = read_data(\"test_data.csv\")\n",
        "df_val = read_data(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_images/Train_images/Cigar-shaped smooth/...</td>\n",
              "      <td>235228</td>\n",
              "      <td>Class0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_images/Train_images/Cigar-shaped smooth/...</td>\n",
              "      <td>624444</td>\n",
              "      <td>Class0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_images/Train_images/Cigar-shaped smooth/...</td>\n",
              "      <td>601143</td>\n",
              "      <td>Class0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_images/Train_images/Cigar-shaped smooth/...</td>\n",
              "      <td>101135</td>\n",
              "      <td>Class0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_images/Train_images/Cigar-shaped smooth/...</td>\n",
              "      <td>347906</td>\n",
              "      <td>Class0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>Train_images/Train_images/spiral/346113.jpg</td>\n",
              "      <td>346113</td>\n",
              "      <td>Class4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>Train_images/Train_images/spiral/332813.jpg</td>\n",
              "      <td>332813</td>\n",
              "      <td>Class4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>Train_images/Train_images/spiral/149207.jpg</td>\n",
              "      <td>149207</td>\n",
              "      <td>Class4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2877</th>\n",
              "      <td>Train_images/Train_images/spiral/364853.jpg</td>\n",
              "      <td>364853</td>\n",
              "      <td>Class4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2878</th>\n",
              "      <td>Train_images/Train_images/spiral/935436.jpg</td>\n",
              "      <td>935436</td>\n",
              "      <td>Class4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2879 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   path   index   label\n",
              "0     Train_images/Train_images/Cigar-shaped smooth/...  235228  Class0\n",
              "1     Train_images/Train_images/Cigar-shaped smooth/...  624444  Class0\n",
              "2     Train_images/Train_images/Cigar-shaped smooth/...  601143  Class0\n",
              "3     Train_images/Train_images/Cigar-shaped smooth/...  101135  Class0\n",
              "4     Train_images/Train_images/Cigar-shaped smooth/...  347906  Class0\n",
              "...                                                 ...     ...     ...\n",
              "2874        Train_images/Train_images/spiral/346113.jpg  346113  Class4\n",
              "2875        Train_images/Train_images/spiral/332813.jpg  332813  Class4\n",
              "2876        Train_images/Train_images/spiral/149207.jpg  149207  Class4\n",
              "2877        Train_images/Train_images/spiral/364853.jpg  364853  Class4\n",
              "2878        Train_images/Train_images/spiral/935436.jpg  935436  Class4\n",
              "\n",
              "[2879 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data logging and input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from uuid import uuid4\n",
        "\n",
        "\n",
        "def create_vector_metadata_dict():\n",
        "    if not os.path.exists(\"pipelines\"):\n",
        "        os.makedirs(\"pipelines\")\n",
        "    # create a dictionary to store the metadata of the vectors\n",
        "    if not os.path.exists(\"pipelines/metadata.json\"):\n",
        "        vector_metadata = dict()\n",
        "        with open(\"pipelines/metadata.json\", \"w\") as file:\n",
        "            file.write(json.dumps(vector_metadata))\n",
        "\n",
        "\n",
        "def read_vector_metadata_dict(vector_attributes: dict) -> pd.DataFrame | None:\n",
        "    \"\"\"\n",
        "    Vector metadata dict should be a dictionary with keys as names of the uuid vector csv files,\n",
        "    and values as dictionaries with keys as the metadata of the vector csv.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"pipelines/metadata.json\"):\n",
        "        create_vector_metadata_dict()\n",
        "    with open(\"pipelines/metadata.json\", \"r\") as file:\n",
        "        vector_metadata = json.load(file)\n",
        "    # if there is a match, return the csv\n",
        "    for key, value in vector_metadata.items():\n",
        "        if value == vector_attributes:\n",
        "            if os.path.exists(f\"pipelines/{key}\"):\n",
        "                return pd.read_csv(f\"pipelines/{key}\")\n",
        "            # if file doesn't exist, remove the key from the metadata\n",
        "            else:\n",
        "                del vector_metadata[key]\n",
        "                with open(\"pipelines/metadata.json\", \"w\") as file:\n",
        "                    file.write(json.dumps(vector_metadata))\n",
        "                return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def write_vector_metadata_dict(data, vector_attributes: dict) -> None:\n",
        "    \"\"\"\n",
        "    After processing a dataset with a pipeline, take the vector attributes, and save with a unique uuid.\n",
        "    Also save a into the metadata dictionary, with the {uuid}.csv as the key and the vector attributes as the value.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"pipelines/metadata.json\"):\n",
        "        create_vector_metadata_dict()\n",
        "    with open(\"pipelines/metadata.json\", \"r\") as file:\n",
        "        vector_metadata = json.load(file)\n",
        "    # check if there is already a match.  If so, raise an error.\n",
        "    for key, value in vector_metadata.items():\n",
        "        if value == vector_attributes:\n",
        "            raise ValueError(\"Vector metadata already exists\")\n",
        "    # create a unique identifier\n",
        "    uuid = str(uuid4())\n",
        "    # write the data\n",
        "    data.to_csv(f\"pipelines/{uuid}.csv\", index=False)\n",
        "    # write the metadata\n",
        "    vector_metadata[f\"{uuid}.csv\"] = vector_attributes\n",
        "    with open(\"pipelines/metadata.json\", \"w\") as file:\n",
        "        file.write(json.dumps(vector_metadata))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Za9tlbJX8qNt"
      },
      "outputs": [],
      "source": [
        "# preprocess and pipeline\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def grayscale_preprocessing(img):\n",
        "    if np.max(img) > 1:\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "    im_gray = np.mean(img, axis=2)\n",
        "    return im_gray\n",
        "\n",
        "\n",
        "def bilateral_preprocessing(img, ksize, sigmX, sigmY):\n",
        "    bilateral_filtered_image = cv2.bilateralFilter(img, ksize, sigmX, sigmY)\n",
        "    return bilateral_filtered_image\n",
        "\n",
        "\n",
        "def high_pass_preprocessing(img, ksize, sig):\n",
        "    low_pass = cv2.GaussianBlur(img, ksize, 0)\n",
        "    high_pass = img - low_pass\n",
        "    return high_pass\n",
        "\n",
        "\n",
        "def build_codebook(\n",
        "    preprocessed_features,\n",
        "    sample_size=1050,\n",
        "    k=200,\n",
        "    iters=1,\n",
        "    save_location=\"codebook.npy\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Use k-means clustering to build a codebook of visual words, given a set of SIFT descriptors.\n",
        "    Args:\n",
        "            sample_size: number of SIFT descriptors to sample from the training set\n",
        "    \"\"\"\n",
        "    descriptors_sample = list()\n",
        "    descriptor_sample = list()\n",
        "    sample_idx = np.random.randint(0, len(df_train) + 1, sample_size).tolist()\n",
        "    for i in sample_idx:\n",
        "        if (\n",
        "            preprocessed_features[i] is not None\n",
        "            and len(preprocessed_features[i].shape) == 2\n",
        "        ):\n",
        "            descriptors_sample.append(preprocessed_features[i])\n",
        "    descriptor_sample = np.vstack(descriptors_sample)\n",
        "    codebook, variance = kmeans(descriptor_sample, k, iters)\n",
        "    np.save(save_location, codebook)\n",
        "    return codebook\n",
        "\n",
        "\n",
        "def quantize_and_create_sparse_representation(preprocessed_features, codebook):\n",
        "    visual_words = []\n",
        "    frequency_vectors = []\n",
        "    # for each image descriptor, take every idx and\n",
        "    for img_descriptors in preprocessed_features:\n",
        "        if img_descriptors is None:\n",
        "            visual_words.append(np.zeros(200))\n",
        "            continue\n",
        "        img_visual_words, distance = vq(img_descriptors, codebook)\n",
        "        visual_words.append(img_visual_words)\n",
        "    for img_visual_words in visual_words:\n",
        "        # create a frequency vector for each image\n",
        "        img_frequency_vector = np.zeros(200)\n",
        "        for word in img_visual_words:\n",
        "            img_frequency_vector[int(word)] += 1\n",
        "        frequency_vectors.append(img_frequency_vector)\n",
        "    frequency_vectors = np.stack(frequency_vectors)\n",
        "    return frequency_vectors\n",
        "\n",
        "\n",
        "def sift_bag_of_visual_words(img):\n",
        "    sift = cv2.SIFT_create()\n",
        "    image8bit = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(\"uint8\")\n",
        "    keypoints, descriptors = sift.detectAndCompute(image8bit, None)\n",
        "    return descriptors\n",
        "\n",
        "\n",
        "def sobel_preprocessing(img, ksize):\n",
        "    sobelx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=ksize)  # Find x and y gradients\n",
        "    sobely = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=ksize)\n",
        "    magnitude = np.sqrt(sobelx**2.0 + sobely**2.0)\n",
        "    if np.max(magnitude) == 0:\n",
        "        return magnitude\n",
        "    magnitude = magnitude / np.max(magnitude)  # normalize\n",
        "    return magnitude\n",
        "\n",
        "\n",
        "def gaussian_blur_preprocessing(img, ksize, sigma):\n",
        "    blurred_im = cv2.GaussianBlur(img, ksize, sigmaX=sigma[0], sigmaY=sigma[1])\n",
        "    return blurred_im\n",
        "\n",
        "\n",
        "def canny_filter(img, high_threshold, low_threshold):\n",
        "    # ensure the image is normalized to the range [0, 1]\n",
        "    if np.max(img) != 0:\n",
        "        img = img / np.max(img)\n",
        "    # scale the image to the range [0, 255] and convert to 8-bit\n",
        "    img_8u = np.uint8(img * 255)\n",
        "    # threshold the image and get the interesting points\n",
        "    # The high threshold is used to identify the strong edges. Pixels with intensity gradients above this threshold are marked as strong edge pixels.\n",
        "    # The low threshold is used to identify the non-edges. Pixels with intensity gradients below this threshold are suppressed.\n",
        "    # By setting the high threshold too low, many pixels might be considered as strong edges, leading to a noisy edge image. Similarly, if the low threshold is set too high, you might miss genuine weak edges that should contribute to the final edge image.\n",
        "\n",
        "    im_threshold = cv2.Canny(\n",
        "        image=img_8u, threshold1=low_threshold, threshold2=high_threshold\n",
        "    )  # Canny Edge\n",
        "    if np.max(im_threshold) == 0:\n",
        "        return im_threshold\n",
        "    im_threshold = im_threshold / np.max(im_threshold)  # normalize\n",
        "    return im_threshold\n",
        "\n",
        "\n",
        "def crop_center(img, cropx, cropy):\n",
        "    y, x = img.shape\n",
        "    startx = x // 2 - (cropx // 2)\n",
        "    starty = y // 2 - (cropy // 2)\n",
        "    return img[starty : starty + cropy, startx : startx + cropx]\n",
        "\n",
        "\n",
        "def histogram_clipping(img, threshold_value):\n",
        "    clipped_image = img.copy()\n",
        "    # before\n",
        "    # draw_histogram_gray(clipped_image)\n",
        "    clipped_image[img < threshold_value / 255.0] = 0\n",
        "    # Normalize the clipped_image to 0-255 for proper histogram visualization\n",
        "    normalized_clipped_image = cv2.normalize(\n",
        "        clipped_image,\n",
        "        None,\n",
        "        alpha=0,\n",
        "        beta=255,\n",
        "        norm_type=cv2.NORM_MINMAX,\n",
        "        dtype=cv2.CV_8UC1,\n",
        "    )\n",
        "    # draw_histogram_gray(clipped_image)\n",
        "    return normalized_clipped_image\n",
        "\n",
        "\n",
        "def hog(img_gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3)):\n",
        "    block_norm = \"L1\"  # Block normalization method\n",
        "    # orientations = 9   # Number of orientation bins\n",
        "    # pixels_per_cell = (8, 8)  # Size of the cell\n",
        "    # cells_per_block = (3, 3)  # Size of the block\n",
        "\n",
        "    # Compute the HOG features\n",
        "    hog_features, hog_image = feature.hog(\n",
        "        img_gray,\n",
        "        orientations=orientations,\n",
        "        pixels_per_cell=pixels_per_cell,\n",
        "        cells_per_block=cells_per_block,\n",
        "        block_norm=block_norm,\n",
        "        visualize=True,\n",
        "    )\n",
        "    return hog_features, hog_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_1(df, codebook_size=200, codebook=None):\n",
        "    image_dir = df[\"path\"]  # ignore index\n",
        "    preprocessed_list = []\n",
        "    for i, image_path in enumerate(tqdm(image_dir)):\n",
        "        im = np.array(Image.open(image_path))\n",
        "        im = grayscale_preprocessing(im)\n",
        "        im = histogram_clipping(im, 30)\n",
        "        im = gaussian_blur_preprocessing(im, (9, 9), (10, 10))\n",
        "        im = bilateral_preprocessing(im, 5, 30, 30)\n",
        "        im = sobel_preprocessing(im, 31)\n",
        "        # im = canny_filter(im, 70, 0)\n",
        "        im = crop_center(im, 252, 252)\n",
        "        sift = sift_bag_of_visual_words(im)\n",
        "        preprocessed_list.append(sift)\n",
        "    if codebook is None or (\n",
        "        codebook is not None and codebook_size != codebook.shape[0]\n",
        "    ):\n",
        "        codebook = build_codebook(preprocessed_list)\n",
        "    frequency_vectors = quantize_and_create_sparse_representation(\n",
        "        preprocessed_list, codebook\n",
        "    )\n",
        "    max = np.max(frequency_vectors, axis=1)\n",
        "    vector_representations_normalized = frequency_vectors / max[:, np.newaxis]\n",
        "    return vector_representations_normalized\n",
        "\n",
        "\n",
        "def preprocess_2(df):\n",
        "    image_dir = df[\"path\"]\n",
        "    preprocessed_list = []\n",
        "    for i, image_path in enumerate(tqdm(image_dir)):\n",
        "        im = np.array(Image.open(image_path))\n",
        "        im_gray = grayscale_preprocessing(im)\n",
        "        img_histogram_clipping = histogram_clipping(im_gray, 30)\n",
        "        im_blurred = gaussian_blur_preprocessing(\n",
        "            img_histogram_clipping, (9, 9), (10, 10)\n",
        "        )\n",
        "        im_bilateral = bilateral_preprocessing(im_blurred, 5, 30, 30)\n",
        "        im_cropped = crop_center(im_bilateral, 240, 240)\n",
        "        hog_feature, hog_image = hog(im_cropped)  # (63504,)\n",
        "        preprocessed_list.append(hog_feature)\n",
        "    # im_flattened = hog_feature.flatten()\n",
        "    return np.array(preprocessed_list)\n",
        "\n",
        "\n",
        "def preprocess_resnet_nopreprocess(df):\n",
        "    image_dir = df[\"path\"]\n",
        "    preprocessed_list = []\n",
        "    for i, image_path in enumerate(image_dir):\n",
        "        im = np.array(Image.open(image_path))\n",
        "        preprocessed_list.append(im)\n",
        "    return preprocessed_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cEa2rRdK--C8"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def pick_top_feature_pca(feature_matrix, top_components, n_components):\n",
        "    # pick up top 100 features by PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca.fit(feature_matrix)\n",
        "    principal_components = pca.transform(feature_matrix)\n",
        "    top_components_matrix = principal_components[:, :top_components]\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "    plt.xlabel(\"Number of PCA components\")\n",
        "    plt.ylabel(\"Cumulative explained variance\")\n",
        "    plt.title(\"Explained Variance vs Number of PCA Components\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Extract the top n components\n",
        "    return top_components_matrix, pca\n",
        "\n",
        "\n",
        "# use the pca embedding from train and process the val and test\n",
        "def pick_top_feature_pca_val_test(pca_train, feature_matrix, top_components: int):\n",
        "    principal_components = pca_train.transform(feature_matrix)\n",
        "    top_components_matrix = principal_components[:, :top_components]\n",
        "    return top_components_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR9Me8qN9DeY"
      },
      "source": [
        "Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqGHUboQ9CAt",
        "outputId": "2abe06d9-266f-4b37-93ff-2caaf1d36cf0"
      },
      "outputs": [],
      "source": [
        "images_list_nopreprocess = preprocess_resnet_nopreprocess(df_train)\n",
        "print(len(images_list_nopreprocess))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8TT7Pga-Car",
        "outputId": "8368f7d2-6541-4245-90b2-95f2c235121e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2881\n"
          ]
        }
      ],
      "source": [
        "images_list_nopreprocess_val = preprocess_resnet_nopreprocess(df_val)\n",
        "print(len(images_list_nopreprocess_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2879\n"
          ]
        }
      ],
      "source": [
        "images_list_no_preprocess_test = preprocess_resnet_nopreprocess(df_test)\n",
        "print(len(images_list_no_preprocess_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxW9yen59HAq",
        "outputId": "2fe606b5-a955-4e76-e2cc-2e94f4f7120d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ImmanuelDesktop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ImmanuelDesktop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# load pre-trained ResNet model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "# remove the classifier on top of resnet\n",
        "resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
        "# freeze the parameters of the feature extractor\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "# Print the modified ResNet architecture\n",
        "\n",
        "print(resnet)\n",
        "\n",
        "# move the model to GPU\n",
        "device = torch.device(\"cuda\")\n",
        "resnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVKGXiIq9JxF",
        "outputId": "69a8ea13-6e7e-42ef-db6d-4f5225c24b5c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'images_list_nopreprocess' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 45>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         processed_images\u001b[38;5;241m.\u001b[39mappend(processed_image)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_images\n\u001b[1;32m---> 45\u001b[0m custom_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[43mimages_list_nopreprocess\u001b[49m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# create a data loader with batch size\u001b[39;00m\n\u001b[0;32m     48\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'images_list_nopreprocess' is not defined"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# data loader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.fromarray(self.images[idx])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "\n",
        "# transformations to be applied to the images\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        # crop the image to shape of 224,224 in preprocess stage\n",
        "        transforms.Resize(256),  # Step 1: Resize to 256x256\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# function to preprocess an image\n",
        "def preprocess_images(images):\n",
        "    processed_images = []\n",
        "    for img in images:\n",
        "        img = Image.fromarray(img)\n",
        "        processed_image = transform(img).unsqueeze(0)  # Add batch dimension\n",
        "        processed_images.append(processed_image)\n",
        "    return processed_images\n",
        "\n",
        "\n",
        "custom_dataset = CustomDataset(images_list_nopreprocess, transform=transform)\n",
        "\n",
        "# create a data loader with batch size\n",
        "batch_size = 8\n",
        "data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Process images in batches\n",
        "features_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        features = resnet(batch.to(device))\n",
        "        features_list.append(features)\n",
        "\n",
        "# Concatenate features from all batches\n",
        "features = torch.cat(features_list, dim=0)\n",
        "\n",
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWhzTfs_-Rvz",
        "outputId": "9c3c43f7-f093-4669-dc71-17100dee6056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2881, 2048, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# val\n",
        "custom_dataset_val = CustomDataset(images_list_nopreprocess_val, transform=transform)\n",
        "\n",
        "# create a data loader with batch size\n",
        "batch_size = 8\n",
        "data_loader = DataLoader(custom_dataset_val, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Process images in batches\n",
        "features_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        features_val = resnet(batch.to(device))\n",
        "        features_list.append(features_val)\n",
        "\n",
        "# Concatenate features from all batches\n",
        "features_val = torch.cat(features_list, dim=0)\n",
        "\n",
        "print(features_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2879, 2048, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "custom_dataset_test = CustomDataset(images_list_no_preprocess_test,  transform=transform)\n",
        "\n",
        "# create a data loader with batch size\n",
        "batch_size = 8\n",
        "data_loader = DataLoader(custom_dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Process images in batches\n",
        "features_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        features_test = resnet(batch.to(device))\n",
        "        features_list.append(features_test)\n",
        "\n",
        "# Concatenate features from all batches\n",
        "features_test = torch.cat(features_list, dim=0)\n",
        "\n",
        "print(features_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "k_HKOQH09LEf",
        "outputId": "71c7cb99-3e5a-4cbc-fa84-2836af413058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23032, 2048)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.323866</td>\n",
              "      <td>0.810107</td>\n",
              "      <td>0.173423</td>\n",
              "      <td>0.095104</td>\n",
              "      <td>1.097468</td>\n",
              "      <td>0.656244</td>\n",
              "      <td>0.926285</td>\n",
              "      <td>0.419996</td>\n",
              "      <td>0.242248</td>\n",
              "      <td>0.075973</td>\n",
              "      <td>...</td>\n",
              "      <td>0.286544</td>\n",
              "      <td>0.144746</td>\n",
              "      <td>0.071651</td>\n",
              "      <td>0.085822</td>\n",
              "      <td>0.249744</td>\n",
              "      <td>0.175224</td>\n",
              "      <td>0.194063</td>\n",
              "      <td>0.149440</td>\n",
              "      <td>0.253527</td>\n",
              "      <td>0.287767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.281115</td>\n",
              "      <td>0.264574</td>\n",
              "      <td>0.213297</td>\n",
              "      <td>0.429184</td>\n",
              "      <td>0.467649</td>\n",
              "      <td>0.344130</td>\n",
              "      <td>0.255342</td>\n",
              "      <td>0.472110</td>\n",
              "      <td>0.422953</td>\n",
              "      <td>0.362707</td>\n",
              "      <td>...</td>\n",
              "      <td>0.377906</td>\n",
              "      <td>0.482257</td>\n",
              "      <td>0.453984</td>\n",
              "      <td>0.150207</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.071317</td>\n",
              "      <td>0.809006</td>\n",
              "      <td>0.277254</td>\n",
              "      <td>0.585173</td>\n",
              "      <td>0.039033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.301838</td>\n",
              "      <td>0.308071</td>\n",
              "      <td>0.448213</td>\n",
              "      <td>0.638293</td>\n",
              "      <td>0.682398</td>\n",
              "      <td>0.428404</td>\n",
              "      <td>0.524108</td>\n",
              "      <td>0.165699</td>\n",
              "      <td>0.141113</td>\n",
              "      <td>0.928782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.590672</td>\n",
              "      <td>1.031486</td>\n",
              "      <td>0.836792</td>\n",
              "      <td>0.453696</td>\n",
              "      <td>0.654381</td>\n",
              "      <td>0.252695</td>\n",
              "      <td>0.359767</td>\n",
              "      <td>0.298241</td>\n",
              "      <td>0.734670</td>\n",
              "      <td>0.226921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 2048 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0  0.323866  0.810107  0.173423  0.095104  1.097468  0.656244  0.926285   \n",
              "1  0.281115  0.264574  0.213297  0.429184  0.467649  0.344130  0.255342   \n",
              "2  0.301838  0.308071  0.448213  0.638293  0.682398  0.428404  0.524108   \n",
              "\n",
              "       7         8         9     ...      2038      2039      2040      2041  \\\n",
              "0  0.419996  0.242248  0.075973  ...  0.286544  0.144746  0.071651  0.085822   \n",
              "1  0.472110  0.422953  0.362707  ...  0.377906  0.482257  0.453984  0.150207   \n",
              "2  0.165699  0.141113  0.928782  ...  0.590672  1.031486  0.836792  0.453696   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0  0.249744  0.175224  0.194063  0.149440  0.253527  0.287767  \n",
              "1  0.247594  0.071317  0.809006  0.277254  0.585173  0.039033  \n",
              "2  0.654381  0.252695  0.359767  0.298241  0.734670  0.226921  \n",
              "\n",
              "[3 rows x 2048 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "features = features.cpu()\n",
        "# reshape it to 2000,2048\n",
        "reshaped_features = features.squeeze().numpy()\n",
        "reshaped_features = reshaped_features.reshape(reshaped_features.shape[0], -1)\n",
        "# Convert to DataFrame\n",
        "df_features = pd.DataFrame(reshaped_features)\n",
        "# Display the DataFrame\n",
        "print(df_features.shape)\n",
        "df_features.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HcGKJSaMWLHr",
        "outputId": "a413c9cf-b14f-44ad-aef5-36e4e837aba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2881, 2048)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.510134</td>\n",
              "      <td>0.531732</td>\n",
              "      <td>0.564358</td>\n",
              "      <td>0.283559</td>\n",
              "      <td>0.808487</td>\n",
              "      <td>0.199183</td>\n",
              "      <td>0.466298</td>\n",
              "      <td>0.638799</td>\n",
              "      <td>0.302476</td>\n",
              "      <td>0.215067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101773</td>\n",
              "      <td>0.165949</td>\n",
              "      <td>0.674558</td>\n",
              "      <td>0.093893</td>\n",
              "      <td>0.491420</td>\n",
              "      <td>0.060113</td>\n",
              "      <td>0.184774</td>\n",
              "      <td>0.093184</td>\n",
              "      <td>0.187553</td>\n",
              "      <td>0.588974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.218773</td>\n",
              "      <td>0.837910</td>\n",
              "      <td>0.309665</td>\n",
              "      <td>0.228205</td>\n",
              "      <td>0.433090</td>\n",
              "      <td>0.120860</td>\n",
              "      <td>0.068646</td>\n",
              "      <td>0.301544</td>\n",
              "      <td>0.360871</td>\n",
              "      <td>0.045463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265798</td>\n",
              "      <td>0.207874</td>\n",
              "      <td>0.562695</td>\n",
              "      <td>0.231727</td>\n",
              "      <td>0.499461</td>\n",
              "      <td>0.155617</td>\n",
              "      <td>0.662672</td>\n",
              "      <td>0.616920</td>\n",
              "      <td>0.091594</td>\n",
              "      <td>0.181815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.144012</td>\n",
              "      <td>0.165640</td>\n",
              "      <td>0.820923</td>\n",
              "      <td>0.391705</td>\n",
              "      <td>0.238297</td>\n",
              "      <td>0.463936</td>\n",
              "      <td>0.222407</td>\n",
              "      <td>0.588128</td>\n",
              "      <td>0.252694</td>\n",
              "      <td>0.512174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247687</td>\n",
              "      <td>0.360356</td>\n",
              "      <td>0.327505</td>\n",
              "      <td>0.480008</td>\n",
              "      <td>0.321182</td>\n",
              "      <td>0.245446</td>\n",
              "      <td>0.272346</td>\n",
              "      <td>0.515320</td>\n",
              "      <td>0.403950</td>\n",
              "      <td>0.288500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 2048 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0  0.510134  0.531732  0.564358  0.283559  0.808487  0.199183  0.466298   \n",
              "1  0.218773  0.837910  0.309665  0.228205  0.433090  0.120860  0.068646   \n",
              "2  0.144012  0.165640  0.820923  0.391705  0.238297  0.463936  0.222407   \n",
              "\n",
              "       7         8         9     ...      2038      2039      2040      2041  \\\n",
              "0  0.638799  0.302476  0.215067  ...  0.101773  0.165949  0.674558  0.093893   \n",
              "1  0.301544  0.360871  0.045463  ...  0.265798  0.207874  0.562695  0.231727   \n",
              "2  0.588128  0.252694  0.512174  ...  0.247687  0.360356  0.327505  0.480008   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0  0.491420  0.060113  0.184774  0.093184  0.187553  0.588974  \n",
              "1  0.499461  0.155617  0.662672  0.616920  0.091594  0.181815  \n",
              "2  0.321182  0.245446  0.272346  0.515320  0.403950  0.288500  \n",
              "\n",
              "[3 rows x 2048 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_val = features_val.cpu()\n",
        "reshaped_features_val = features_val.squeeze().numpy()\n",
        "reshaped_features_val = reshaped_features_val.reshape(\n",
        "    reshaped_features_val.shape[0], -1\n",
        ")\n",
        "df_features_val = pd.DataFrame(reshaped_features_val)\n",
        "print(df_features_val.shape)\n",
        "df_features_val.head(3)\n",
        "\n",
        "# resnet train: df_features / resnet val: df_features_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2879, 2048)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.071336</td>\n",
              "      <td>0.218844</td>\n",
              "      <td>0.303433</td>\n",
              "      <td>0.448429</td>\n",
              "      <td>1.085989</td>\n",
              "      <td>0.746727</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.739389</td>\n",
              "      <td>0.439367</td>\n",
              "      <td>0.238507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116314</td>\n",
              "      <td>0.395819</td>\n",
              "      <td>0.132275</td>\n",
              "      <td>0.043789</td>\n",
              "      <td>0.358311</td>\n",
              "      <td>0.134943</td>\n",
              "      <td>0.397711</td>\n",
              "      <td>0.186322</td>\n",
              "      <td>0.060069</td>\n",
              "      <td>0.265349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.626142</td>\n",
              "      <td>0.251020</td>\n",
              "      <td>0.864124</td>\n",
              "      <td>0.237185</td>\n",
              "      <td>0.124343</td>\n",
              "      <td>0.903479</td>\n",
              "      <td>0.092782</td>\n",
              "      <td>0.108641</td>\n",
              "      <td>0.576048</td>\n",
              "      <td>0.750469</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071972</td>\n",
              "      <td>0.531990</td>\n",
              "      <td>0.553137</td>\n",
              "      <td>0.576850</td>\n",
              "      <td>0.316697</td>\n",
              "      <td>0.302557</td>\n",
              "      <td>0.296011</td>\n",
              "      <td>0.242232</td>\n",
              "      <td>0.763575</td>\n",
              "      <td>0.747678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.193286</td>\n",
              "      <td>0.750038</td>\n",
              "      <td>0.073023</td>\n",
              "      <td>0.165334</td>\n",
              "      <td>0.748972</td>\n",
              "      <td>0.655146</td>\n",
              "      <td>0.389483</td>\n",
              "      <td>0.693393</td>\n",
              "      <td>0.954382</td>\n",
              "      <td>0.188428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.748377</td>\n",
              "      <td>0.414582</td>\n",
              "      <td>0.113435</td>\n",
              "      <td>0.304529</td>\n",
              "      <td>0.601162</td>\n",
              "      <td>0.199630</td>\n",
              "      <td>0.198217</td>\n",
              "      <td>0.120655</td>\n",
              "      <td>0.307602</td>\n",
              "      <td>0.531466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 2048 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0  0.071336  0.218844  0.303433  0.448429  1.085989  0.746727  0.511905   \n",
              "1  0.626142  0.251020  0.864124  0.237185  0.124343  0.903479  0.092782   \n",
              "2  0.193286  0.750038  0.073023  0.165334  0.748972  0.655146  0.389483   \n",
              "\n",
              "       7         8         9     ...      2038      2039      2040      2041  \\\n",
              "0  0.739389  0.439367  0.238507  ...  0.116314  0.395819  0.132275  0.043789   \n",
              "1  0.108641  0.576048  0.750469  ...  0.071972  0.531990  0.553137  0.576850   \n",
              "2  0.693393  0.954382  0.188428  ...  0.748377  0.414582  0.113435  0.304529   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0  0.358311  0.134943  0.397711  0.186322  0.060069  0.265349  \n",
              "1  0.316697  0.302557  0.296011  0.242232  0.763575  0.747678  \n",
              "2  0.601162  0.199630  0.198217  0.120655  0.307602  0.531466  \n",
              "\n",
              "[3 rows x 2048 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_test = features_test.cpu()\n",
        "reshaped_features_test = features_test.squeeze().numpy()\n",
        "reshaped_features_test = reshaped_features_test.reshape(\n",
        "    reshaped_features_test.shape[0], -1\n",
        ")\n",
        "df_features_test = pd.DataFrame(reshaped_features_test)\n",
        "print(df_features_test.shape)\n",
        "df_features_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYwQLWv3BORx",
        "outputId": "d444b243-d49c-4acf-eac9-ba0581958921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23032, 2048)\n"
          ]
        }
      ],
      "source": [
        "Y_train_resnet = df_train[\"label\"]\n",
        "X_train_resnet = df_features\n",
        "print(X_train_resnet.shape)\n",
        "Y_val_resnet = df_val[\"label\"]\n",
        "X_val_resnet = df_features_val\n",
        "print(X_val_resnet.shape)\n",
        "Y_test_resnet = df_test[\"label\"]\n",
        "X_test_resnet = df_features_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGiykvBgBx8F",
        "outputId": "afc58caf-69bd-4273-eee0-6b63a1ec20a3"
      },
      "outputs": [],
      "source": [
        "# save the features\n",
        "np.save(\"pipeline3_train.npy\", X_train_resnet)\n",
        "np.save(\"pipeline3_val.npy\", X_val_resnet)\n",
        "np.save(\"pipeline3_test.npy\", X_test_resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKWDpsUu9WVI"
      },
      "source": [
        "Pipeline1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hfx5I8j9Xx-",
        "outputId": "126fe1af-bcaf-41ac-b8c9-ec1d67d85d1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23032/23032 [05:21<00:00, 71.66it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(23032, 200)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_features = preprocess_1(df_train)\n",
        "preprocessed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq_D4gen-ynh",
        "outputId": "7ecc5233-5ec6-4594-a701-78c46ba13c42"
      },
      "outputs": [],
      "source": [
        "with open(\"codebook.npy\", \"rb\") as f:\n",
        "    codebook = np.load(f)\n",
        "preprocessed_features_val = preprocess_1(df_val, codebook=codebook)\n",
        "preprocessed_features_val.shape\n",
        "\n",
        "# pipeline1 train: preprocessed_features / pipeline1 val: preprocessed_features_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-t7i5veAANVl"
      },
      "outputs": [],
      "source": [
        "Y_train_pipeline1 = df_train[\"label\"]\n",
        "# max = np.max(preprocessed_features, axis=1)\n",
        "# vector_representations_normalized = preprocessed_features / max[:, np.newaxis]\n",
        "X_train_pipeline1 = preprocessed_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "t6jcOyOaAgQD"
      },
      "outputs": [],
      "source": [
        "Y_val_pipeline1 = df_val[\"label\"]\n",
        "# max_val = np.max(preprocessed_features_val, axis=1)\n",
        "# vector_representations_normalized_val = preprocessed_features_val / max_val[:, np.newaxis]\n",
        "x_val_pipeline1 = preprocessed_features_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_test_pipeline1 = df_test[\"label\"]\n",
        "preprocessed_features_test = preprocess_1(df_test, codebook=codebook)\n",
        "x_test_pipeline1 = preprocessed_features_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# export the pipeline1 features\n",
        "np.save(\"pipeline1_train.npy\", X_train_pipeline1)\n",
        "np.save(\"pipeline1_val.npy\", x_val_pipeline1)\n",
        "np.save(\"pipeline1_test.npy\", preprocessed_features_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTATJY27Coui"
      },
      "source": [
        "pipeline 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiAFgWJBCq1T",
        "outputId": "e928d84a-6b3e-47e8-eb5a-a5ad773d6808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23032/23032 [1:09:29<00:00,  5.52it/s]\n"
          ]
        }
      ],
      "source": [
        "df_preprocessed_2_train = preprocess_2(df_train)\n",
        "# df_preprocessed_2_train.columns = [\n",
        "#     f\"feature_{i}\" for i in range(len(df_preprocessed_2_train.columns))\n",
        "# ]\n",
        "# print(df_preprocessed_2_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2881/2881 [08:13<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2881, 63504)\n"
          ]
        }
      ],
      "source": [
        "df_preprocessed_2_val = preprocess_2(df_val)\n",
        "# df_preprocessed_2_val.columns = [\n",
        "#    f\"feature_{i}\" for i in range(len(df_preprocessed_2_val.columns))\n",
        "# ]\n",
        "print(df_preprocessed_2_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2879/2879 [09:31<00:00,  5.04it/s]\n"
          ]
        }
      ],
      "source": [
        "df_preprocessed_3_test = preprocess_2(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"pipeline2_train_before_pca_and_normalization.npy\", df_preprocessed_2_train)\n",
        "np.save(\"pipeline2_val_before_pca_and_normalization.npy\", df_preprocessed_2_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_preprocessed_2_train = np.load(\"pipeline2_train_before_pca_and_normalization.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# feature normarlization since we only pick up top 200. z score normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def feature_normalization(df_feature, scaler=None):\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(df_feature)\n",
        "    normalized_features = scaler.transform(df_feature)\n",
        "    return normalized_features, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save pre_pca_vectors\n",
        "# df_preprocessed_2_train_normalized, scaler = feature_normalization(df_preprocessed_2_train)\n",
        "# df_preprocessed_2_val_normalized, scaler = feature_normalization(df_preprocessed_2_val, scaler)\n",
        "# np.save(\"pipeline2_pre_normalize_train.npy\", df_preprocessed_2_train)\n",
        "# np.save(\"pipeline2_pre_normalize_val.npy\", df_preprocessed_2_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_preprocessed_2_train = np.load(\"pipeline2_train_before_pca_and_normalization.npy\")\n",
        "df_preprocessed_2_val = np.load(\"pipeline2_val_before_pca_and_normalization.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "del df_preprocessed_2_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "pCn1SZiyDUas",
        "outputId": "dba44446-4c3d-40f7-b8db-d903d21a8f99"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array([[-1.51278373, -1.36087422, -1.70210564, ...,  0.19310535,\n",
              "         0.12897223, -0.03862977],\n",
              "       [-1.68295798, -1.71877398,  0.95844495, ..., -0.04026734,\n",
              "        -0.03568577,  0.0368037 ],\n",
              "       [-1.10722821, -2.1972178 , -0.8681767 , ..., -0.16624584,\n",
              "        -0.13546704,  0.0233147 ]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features = df_preprocessed_2_train\n",
        "val_features = df_preprocessed_2_val\n",
        "test_features = df_preprocessed_3_test\n",
        "top_components = 500\n",
        "hog_train_pca_feature, pca_train_hog = pick_top_feature_pca(\n",
        "    train_features, top_components, 500\n",
        ")\n",
        "# Convert PCA transformed features to DataFrame\n",
        "df_top_100_feature_pca_hog_train = hog_train_pca_feature\n",
        "df_top_100_feature_pca_hog_train[:3, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.32370818,  0.2830298 , -1.91650369, ..., -0.05033526,\n",
              "        -0.08172554, -0.12044734],\n",
              "       [-1.84057534, -0.47753398,  1.79033502, ...,  0.04206816,\n",
              "        -0.05891348, -0.03827909],\n",
              "       [-1.58385394, -1.77813178,  0.77185801, ..., -0.15716013,\n",
              "        -0.067156  , -0.0365625 ]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hog_val_pca_feature = pick_top_feature_pca_val_test(\n",
        "    pca_train_hog, val_features, top_components\n",
        ")\n",
        "df_top_100_feature_pca_hog_val = hog_val_pca_feature\n",
        "df_top_100_feature_pca_hog_val[:3, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.50212802,  1.70991845, -0.24471797, ...,  0.03503824,\n",
              "        -0.01750141, -0.16257448],\n",
              "       [-1.58840103, -2.05178394, -0.89973221, ..., -0.11669538,\n",
              "         0.15000381,  0.29031861],\n",
              "       [-1.96634228,  1.3043201 , -0.2638881 , ..., -0.08904858,\n",
              "        -0.04828058, -0.0659168 ]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hog_test_pca_feature = pick_top_feature_pca_val_test(\n",
        "    pca_train_hog, test_features, top_components\n",
        ")\n",
        "df_top_100_feature_pca_hog_test = hog_test_pca_feature\n",
        "df_top_100_feature_pca_hog_test[:3, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "B-Ml_Yz-EETY"
      },
      "outputs": [],
      "source": [
        "df_top_100_feature_pca_hog_train_normalized, scaler = feature_normalization(\n",
        "    df_top_100_feature_pca_hog_train\n",
        ")\n",
        "df_top_100_feature_pca_hog_val_normalized, scaler = feature_normalization(\n",
        "    df_top_100_feature_pca_hog_val, scaler=scaler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_top_100_feature_pca_hog_test_normalized, scaler = feature_normalization(\n",
        "\tdf_top_100_feature_pca_hog_test, scaler=scaler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the pipeline2 features\n",
        "np.save(\"pipeline2_train.npy\", df_top_100_feature_pca_hog_train_normalized)\n",
        "np.save(\"pipeline2_val.npy\", df_top_100_feature_pca_hog_val_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"pipeline2_test.npy\", df_top_100_feature_pca_hog_test_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading from previously created models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_top_100_feature_pca_hog_train_normalized = np.load(\"pipeline2_train.npy\")\n",
        "df_top_100_feature_pca_hog_val_normalized = np.load(\"pipeline2_val.npy\")\n",
        "df_top_100_feature_pca_hog_test_normalized = np.load(\"pipeline2_test.npy\")\n",
        "X_train_pipeline1 = np.load(\"pipeline1_train.npy\")\n",
        "x_val_pipeline1 = np.load(\"pipeline1_val.npy\")\n",
        "X_test_pipeline1 = np.load(\"pipeline1_test.npy\")\n",
        "X_train_resnet = np.load(\"pipeline3_train.npy\")\n",
        "X_val_resnet = np.load(\"pipeline3_val.npy\")\n",
        "X_test_resnet = np.load(\"pipeline3_test.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dkRwjL1kEM-7"
      },
      "outputs": [],
      "source": [
        "Y_train_hog = df_train[\"label\"]\n",
        "X_train_hog = df_top_100_feature_pca_hog_train_normalized\n",
        "Y_val_hog = df_val[\"label\"]\n",
        "X_val_hog = df_top_100_feature_pca_hog_val_normalized\n",
        "Y_test_hog = df_test[\"label\"]\n",
        "X_test_hog = df_top_100_feature_pca_hog_test_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsrDgjAUEwN-",
        "outputId": "7431c87b-1c7b-44db-ac71-5cad4dce6e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23032, 200) (23032, 500) (23032, 2048)\n",
            "(2881, 200) (2881, 500) (2881, 2048)\n",
            "(2879, 200) (2879, 500) (2879, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_pipeline1.shape, X_train_hog.shape, X_train_resnet.shape)\n",
        "print(x_val_pipeline1.shape, X_val_hog.shape, X_val_resnet.shape)\n",
        "print(X_test_pipeline1.shape, X_test_hog.shape, X_test_resnet.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWASURuhEecf"
      },
      "source": [
        "Combine all three sets of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lqY6ThEEjXA",
        "outputId": "e0f92f31-d913-4206-e551-f606011d6f2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23032, 2748) (2881, 2748) (2879, 2748) (23032,) (2881,) (2879,)\n"
          ]
        }
      ],
      "source": [
        "Y_train = df_train[\"label\"]\n",
        "Y_val = df_val[\"label\"]\n",
        "Y_test = df_test[\"label\"]\n",
        "\n",
        "X_train = np.hstack([X_train_pipeline1, X_train_hog, X_train_resnet])\n",
        "X_val = np.hstack([x_val_pipeline1, X_val_hog, X_val_resnet])\n",
        "X_test = np.hstack([X_test_pipeline1, X_test_hog, X_test_resnet])\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6h31oz6X6iC"
      },
      "source": [
        "Post PCA (just wanna see the variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "SplcFE_5Xtp5",
        "outputId": "89d9a22f-7476-46a1-92a6-d002027c0dfd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "top_components = 200\n",
        "allpipeline_feature_train_pca, pca_all = pick_top_feature_pca(\n",
        "    X_train, top_components, 500\n",
        ")\n",
        "allpipeline_feature_val_pca = pick_top_feature_pca_val_test(\n",
        "    pca_all, X_val, top_components\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iNn5_JrPY2YH"
      },
      "outputs": [],
      "source": [
        "# X_train = allpipeline_feature_train_pca\n",
        "# X_val = allpipeline_feature_val_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI25QSopPcVR"
      },
      "source": [
        "LDA + linear regression, cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JM1gO2IPe3h",
        "outputId": "bd0abe34-aa67-4cf3-b303-f9edef46af94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy: 0.9214571031608197\n",
            "cross-val accuracy: 0.9215437702128038\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# LDA to reduce the dimension to number of class - 1\n",
        "lda = LinearDiscriminantAnalysis(n_components=4)\n",
        "X_train_lda = lda.fit_transform(X_train, Y_train)\n",
        "X_val_lda = lda.transform(X_val)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "# Logistic Regression with L1 regularization\n",
        "# [0.001, 0.01, 0.1, 1]\n",
        "classifier_l1 = LogisticRegression(penalty=\"l1\", C=1, solver=\"liblinear\")\n",
        "classifier_l1.fit(X_train_lda, Y_train)\n",
        "\n",
        "# training accuracy\n",
        "y_pred = classifier_l1.predict(X_train_lda)\n",
        "# evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(Y_train, y_pred)\n",
        "print(\"training accuracy:\", accuracy)\n",
        "\n",
        "cv_scores = cross_val_score(classifier_l1, X_train_lda, Y_train, cv=5)\n",
        "print(\"cross-val accuracy:\", cv_scores.mean())\n",
        "\n",
        "# before grid search\n",
        "# n_componentsint = 4\n",
        "# training accuracy: 0.8975\n",
        "# cross-val accuracy: 0.8924999999999998\n",
        "\n",
        "# n_componentsint = 3\n",
        "# training accuracy: 0.884\n",
        "# cross-val accuracy: 0.882"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LDA + linear regression on validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val accuracy: 0.8840680319333565\n",
            "test accuracy: 0.8933657519972212\n",
            "cross-val accuracy: 0.8875373098401695\n"
          ]
        }
      ],
      "source": [
        "y_val_pred = classifier_l1.predict(X_val_lda)\n",
        "y_test_pred = classifier_l1.predict(X_test_lda)\n",
        "print(\"val accuracy:\", accuracy_score(Y_val, y_val_pred))\n",
        "print(\"test accuracy:\", accuracy_score(Y_test, y_test_pred))\n",
        "print(\"cross-val accuracy:\", cross_val_score(classifier_l1, X_val_lda, Y_val, cv=5).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xQRiARoTQhNi",
        "outputId": "30ad8ebf-9aa8-4bc8-a7bd-695e56ec2374"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compute confusion matrixy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m conf_matrix_val \u001b[38;5;241m=\u001b[39m confusion_matrix(Y_train, classifier_l1\u001b[38;5;241m.\u001b[39mpredict(X_train_lda))\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute confusion matrixy\n",
        "conf_matrix_val = confusion_matrix(Y_train, classifier_l1.predict(X_train_lda))\n",
        "conf_matrix_train = confusion_matrix(Y_val, classifier_l1.predict(X_val_lda))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_train, annot=True, cmap=\"Blues\", fmt=\"g\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_val, annot=True, cmap=\"Blues\", fmt=\"g\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWBf830sRI7j"
      },
      "source": [
        "SVM, cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umqRCkNJRJ4g",
        "outputId": "52a353b0-f2c9-414b-f840-324cd313c0d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy: 0.9995658214657868\n",
            "cross-val accuracy: 0.8872872380482381\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# train the SVM classifier\n",
        "# C is a hyperparameter that controls the trade-off between maximizing the margin and minimizing the classification error.\n",
        "# C represents the inverse of the regularization strength—smaller, C implies more regularization, larger, C implies less regularization\n",
        "# poly, rbf, linear\n",
        "svm_classifier = SVC(kernel=\"rbf\", C=5, gamma=0.001)\n",
        "svm_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# training accuracy\n",
        "y_pred = svm_classifier.predict(X_train)\n",
        "# evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(Y_train, y_pred)\n",
        "print(\"training accuracy:\", accuracy)\n",
        "\n",
        "cv_scores = cross_val_score(svm_classifier, X_train, Y_train, cv=5)\n",
        "print(\"cross-val accuracy:\", cv_scores.mean())\n",
        "\n",
        "# before grid search C = 1\n",
        "# training accuracy: 0.9875\n",
        "# cross-val accuracy: 0.7090000000000001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "divzOO7RRUEk",
        "outputId": "0d7ddfb7-1642-47a6-a6b4-e529c80658ff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute confusion matrixy\n",
        "conf_matrix_val = confusion_matrix(Y_train, svm_classifier.predict(X_train))\n",
        "conf_matrix_train = confusion_matrix(Y_val, svm_classifier.predict(X_val))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_train, annot=True, cmap=\"Blues\", fmt=\"g\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_val, annot=True, cmap=\"Blues\", fmt=\"g\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeBPLkPFTwje"
      },
      "source": [
        "## Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from cuml.metrics.accuracy import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "import gc\n",
        "def accuracy_score_wrapper(y, y_hat):\n",
        "    \"\"\"\n",
        "    A wrapper function to convert labels to float32,\n",
        "    and pass it to accuracy_score.\n",
        "\n",
        "    Params:\n",
        "    - y: The y labels that need to be converted\n",
        "    - y_hat: The predictions made by the model\n",
        "    \"\"\"\n",
        "    gc.collect()\n",
        "    y = y.astype(\"float32\")  # cuML RandomForest needs the y labels to be float32\n",
        "    return accuracy_score(y, y_hat, convert_dtype=True)\n",
        "\n",
        "accuracy_wrapper_scorer = make_scorer(accuracy_score_wrapper)\n",
        "cuml_accuracy_scorer = make_scorer(accuracy_score, convert_dtype=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cuml\n",
        "cuml.common.logger.set_level(1)\n",
        "from cuml.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y_train_cupy = le.fit_transform(Y_train)\n",
        "Y_train = Y_train_cupy.to_numpy()\n",
        "Y_val_cupy = le.transform(Y_val)\n",
        "Y_val = Y_val_cupy.to_numpy()\n",
        "Y_test_cupy = le.transform(Y_test)\n",
        "Y_test = Y_test_cupy.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class GarbageCollector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    cuml is allocating models on heap memory and it is not being GCed with every gridsearch iteration.\n",
        "    Forcibly release the memory by calling gc.collect() after every fit and transform.\n",
        "    Include in gridsearch pipeline.\n",
        "\t\"\"\"\n",
        "    def __init__(self):\n",
        "        self.variables = 'tes'\n",
        "    def fit(self, X, y = None):\n",
        "        gc.collect()\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        gc.collect()\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy: 0.9995658214657868\n",
            "cross-val accuracy: 0.8872872114181518\n",
            "val accuracy: 0.8982992016660881\n",
            "test accuracy: 0.8996179228898923\n"
          ]
        }
      ],
      "source": [
        "# GPU SVM\n",
        "from cuml.svm import SVC\n",
        "cuml.common.logger.set_level(1)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# train the SVM classifier\n",
        "# C is a hyperparameter that controls the trade-off between maximizing the margin and minimizing the classification error.\n",
        "# C represents the inverse of the regularization strength—smaller, C implies more regularization, larger, C implies less regularization\n",
        "# poly, rbf, linear\n",
        "svm_classifier = SVC(kernel=\"rbf\", C=5, gamma=0.001, verbose = 2)\n",
        "svm_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# training accuracy\n",
        "y_pred = svm_classifier.predict(X_train)\n",
        "# evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(Y_train, y_pred)\n",
        "print(\"training accuracy:\", accuracy)\n",
        "\n",
        "cv_scores = cross_val_score(svm_classifier, X_train, Y_train, cv=5)\n",
        "print(\"cross-val accuracy:\", cv_scores.mean())\n",
        "val_score = accuracy_score(Y_val, svm_classifier.predict(X_val))\n",
        "print(\"val accuracy:\", val_score)\n",
        "test_score = accuracy_score(Y_test, svm_classifier.predict(X_test))\n",
        "print(\"test accuracy:\", test_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "dW4uDHs7UDTX",
        "outputId": "47e685a7-5da6-47dd-9fdd-6052eb4ee82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
            "[CV 1/5; 1/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf..............\n",
            "[CV 1/5; 1/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.843 total time=   9.0s\n",
            "[CV 2/5; 1/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf..............\n",
            "[CV 2/5; 1/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.848 total time=   8.0s\n",
            "[CV 3/5; 1/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf..............\n",
            "[CV 3/5; 1/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.845 total time=   8.1s\n",
            "[CV 4/5; 1/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf..............\n",
            "[CV 4/5; 1/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.855 total time=   8.2s\n",
            "[CV 5/5; 1/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf..............\n",
            "[CV 5/5; 1/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.839 total time=   8.1s\n",
            "[CV 1/5; 2/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=poly.............\n",
            "[CV 1/5; 2/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=poly;, score=0.849 total time=   9.5s\n",
            "[CV 2/5; 2/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=poly.............\n",
            "[CV 2/5; 2/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=poly;, score=0.859 total time=   9.6s\n",
            "[CV 3/5; 2/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=poly.............\n",
            "[CV 3/5; 2/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=poly;, score=0.858 total time=   9.6s\n",
            "[CV 4/5; 2/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=poly.............\n",
            "[CV 4/5; 2/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=poly;, score=0.865 total time=   9.4s\n",
            "[CV 5/5; 2/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=poly.............\n",
            "[CV 5/5; 2/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=poly;, score=0.855 total time=   9.5s\n",
            "[CV 1/5; 3/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid..........\n",
            "[CV 1/5; 3/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.819 total time=   7.3s\n",
            "[CV 2/5; 3/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid..........\n",
            "[CV 2/5; 3/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.822 total time=   7.4s\n",
            "[CV 3/5; 3/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid..........\n",
            "[CV 3/5; 3/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.822 total time=   7.2s\n",
            "[CV 4/5; 3/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid..........\n",
            "[CV 4/5; 3/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.826 total time=   7.5s\n",
            "[CV 5/5; 3/60] START svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid..........\n",
            "[CV 5/5; 3/60] END svm__C=0.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.822 total time=   7.1s\n",
            "[CV 1/5; 4/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf...............\n",
            "[CV 1/5; 4/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 2/5; 4/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf...............\n",
            "[CV 2/5; 4/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  13.2s\n",
            "[CV 3/5; 4/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf...............\n",
            "[CV 3/5; 4/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 4/5; 4/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf...............\n",
            "[CV 4/5; 4/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 5/5; 4/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf...............\n",
            "[CV 5/5; 4/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  13.4s\n",
            "[CV 1/5; 5/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=poly..............\n",
            "[CV 1/5; 5/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=poly;, score=0.878 total time=  10.7s\n",
            "[CV 2/5; 5/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=poly..............\n",
            "[CV 2/5; 5/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=poly;, score=0.888 total time=  11.0s\n",
            "[CV 3/5; 5/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=poly..............\n",
            "[CV 3/5; 5/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 4/5; 5/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=poly..............\n",
            "[CV 4/5; 5/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=poly;, score=0.887 total time=  10.8s\n",
            "[CV 5/5; 5/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=poly..............\n",
            "[CV 5/5; 5/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 1/5; 6/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 6/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.292 total time=   8.5s\n",
            "[CV 2/5; 6/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 6/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.287 total time=   8.4s\n",
            "[CV 3/5; 6/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 6/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.289 total time=   8.6s\n",
            "[CV 4/5; 6/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 6/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.288 total time=   8.4s\n",
            "[CV 5/5; 6/60] START svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 6/60] END svm__C=0.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.287 total time=   8.4s\n",
            "[CV 1/5; 7/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf................\n",
            "[CV 1/5; 7/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  13.5s\n",
            "[CV 2/5; 7/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf................\n",
            "[CV 2/5; 7/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 3/5; 7/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf................\n",
            "[CV 3/5; 7/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 4/5; 7/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf................\n",
            "[CV 4/5; 7/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  13.8s\n",
            "[CV 5/5; 7/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf................\n",
            "[CV 5/5; 7/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  13.5s\n",
            "[CV 1/5; 8/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=poly...............\n",
            "[CV 1/5; 8/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=poly;, score=0.878 total time=  10.6s\n",
            "[CV 2/5; 8/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=poly...............\n",
            "[CV 2/5; 8/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=poly;, score=0.888 total time=  10.7s\n",
            "[CV 3/5; 8/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=poly...............\n",
            "[CV 3/5; 8/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  10.7s\n",
            "[CV 4/5; 8/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=poly...............\n",
            "[CV 4/5; 8/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=poly;, score=0.887 total time=  10.9s\n",
            "[CV 5/5; 8/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=poly...............\n",
            "[CV 5/5; 8/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  11.0s\n",
            "[CV 1/5; 9/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid............\n",
            "[CV 1/5; 9/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   7.8s\n",
            "[CV 2/5; 9/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid............\n",
            "[CV 2/5; 9/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 3/5; 9/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid............\n",
            "[CV 3/5; 9/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 4/5; 9/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid............\n",
            "[CV 4/5; 9/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 5/5; 9/60] START svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid............\n",
            "[CV 5/5; 9/60] END svm__C=0.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   7.8s\n",
            "[CV 1/5; 10/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 1/5; 10/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.6s\n",
            "[CV 2/5; 10/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 2/5; 10/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.4s\n",
            "[CV 3/5; 10/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 3/5; 10/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.4s\n",
            "[CV 4/5; 10/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 4/5; 10/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.5s\n",
            "[CV 5/5; 10/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 5/5; 10/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.5s\n",
            "[CV 1/5; 11/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 1/5; 11/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=poly;, score=0.878 total time=  11.0s\n",
            "[CV 2/5; 11/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 2/5; 11/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=poly;, score=0.888 total time=  10.7s\n",
            "[CV 3/5; 11/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 3/5; 11/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 4/5; 11/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 4/5; 11/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=poly;, score=0.887 total time=  10.9s\n",
            "[CV 5/5; 11/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 5/5; 11/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  10.8s\n",
            "[CV 1/5; 12/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 12/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 2/5; 12/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 12/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 3/5; 12/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 12/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   7.9s\n",
            "[CV 4/5; 12/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 12/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 5/5; 12/60] START svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 12/60] END svm__C=0.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 1/5; 13/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf............\n",
            "[CV 1/5; 13/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf;, score=0.856 total time=   8.7s\n",
            "[CV 2/5; 13/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf............\n",
            "[CV 2/5; 13/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf;, score=0.860 total time=   8.5s\n",
            "[CV 3/5; 13/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf............\n",
            "[CV 3/5; 13/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf;, score=0.855 total time=   9.2s\n",
            "[CV 4/5; 13/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf............\n",
            "[CV 4/5; 13/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf;, score=0.867 total time=   9.2s\n",
            "[CV 5/5; 13/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf............\n",
            "[CV 5/5; 13/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=rbf;, score=0.853 total time=   8.7s\n",
            "[CV 1/5; 14/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=poly...........\n",
            "[CV 1/5; 14/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=poly;, score=0.864 total time=  10.2s\n",
            "[CV 2/5; 14/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=poly...........\n",
            "[CV 2/5; 14/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=poly;, score=0.871 total time=  10.6s\n",
            "[CV 3/5; 14/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=poly...........\n",
            "[CV 3/5; 14/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=poly;, score=0.867 total time=  10.5s\n",
            "[CV 4/5; 14/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=poly...........\n",
            "[CV 4/5; 14/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=poly;, score=0.875 total time=  10.4s\n",
            "[CV 5/5; 14/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=poly...........\n",
            "[CV 5/5; 14/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=poly;, score=0.864 total time=  10.5s\n",
            "[CV 1/5; 15/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid........\n",
            "[CV 1/5; 15/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.825 total time=   7.7s\n",
            "[CV 2/5; 15/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid........\n",
            "[CV 2/5; 15/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.829 total time=   7.6s\n",
            "[CV 3/5; 15/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid........\n",
            "[CV 3/5; 15/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.822 total time=   7.4s\n",
            "[CV 4/5; 15/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid........\n",
            "[CV 4/5; 15/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.828 total time=   7.5s\n",
            "[CV 5/5; 15/60] START svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid........\n",
            "[CV 5/5; 15/60] END svm__C=0.75, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.823 total time=   7.5s\n",
            "[CV 1/5; 16/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf.............\n",
            "[CV 1/5; 16/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  14.3s\n",
            "[CV 2/5; 16/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf.............\n",
            "[CV 2/5; 16/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  14.5s\n",
            "[CV 3/5; 16/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf.............\n",
            "[CV 3/5; 16/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  14.3s\n",
            "[CV 4/5; 16/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf.............\n",
            "[CV 4/5; 16/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  14.6s\n",
            "[CV 5/5; 16/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf.............\n",
            "[CV 5/5; 16/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=rbf;, score=0.293 total time=  14.2s\n",
            "[CV 1/5; 17/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=poly............\n",
            "[CV 1/5; 17/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=poly;, score=0.878 total time=  11.3s\n",
            "[CV 2/5; 17/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=poly............\n",
            "[CV 2/5; 17/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=poly;, score=0.888 total time=  11.3s\n",
            "[CV 3/5; 17/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=poly............\n",
            "[CV 3/5; 17/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  11.0s\n",
            "[CV 4/5; 17/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=poly............\n",
            "[CV 4/5; 17/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=poly;, score=0.887 total time=  11.4s\n",
            "[CV 5/5; 17/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=poly............\n",
            "[CV 5/5; 17/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  11.2s\n",
            "[CV 1/5; 18/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid.........\n",
            "[CV 1/5; 18/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.329 total time=   8.8s\n",
            "[CV 2/5; 18/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid.........\n",
            "[CV 2/5; 18/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.331 total time=   9.5s\n",
            "[CV 3/5; 18/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid.........\n",
            "[CV 3/5; 18/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.325 total time=   9.0s\n",
            "[CV 4/5; 18/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid.........\n",
            "[CV 4/5; 18/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.327 total time=   8.7s\n",
            "[CV 5/5; 18/60] START svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid.........\n",
            "[CV 5/5; 18/60] END svm__C=0.75, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.317 total time=   8.9s\n",
            "[CV 1/5; 19/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf..............\n",
            "[CV 1/5; 19/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  14.6s\n",
            "[CV 2/5; 19/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf..............\n",
            "[CV 2/5; 19/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  14.3s\n",
            "[CV 3/5; 19/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf..............\n",
            "[CV 3/5; 19/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  14.4s\n",
            "[CV 4/5; 19/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf..............\n",
            "[CV 4/5; 19/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  14.2s\n",
            "[CV 5/5; 19/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf..............\n",
            "[CV 5/5; 19/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  14.5s\n",
            "[CV 1/5; 20/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=poly.............\n",
            "[CV 1/5; 20/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=poly;, score=0.878 total time=  11.1s\n",
            "[CV 2/5; 20/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=poly.............\n",
            "[CV 2/5; 20/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=poly;, score=0.888 total time=  11.3s\n",
            "[CV 3/5; 20/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=poly.............\n",
            "[CV 3/5; 20/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  11.2s\n",
            "[CV 4/5; 20/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=poly.............\n",
            "[CV 4/5; 20/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=poly;, score=0.887 total time=  11.1s\n",
            "[CV 5/5; 20/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=poly.............\n",
            "[CV 5/5; 20/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  11.4s\n",
            "[CV 1/5; 21/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid..........\n",
            "[CV 1/5; 21/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 2/5; 21/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid..........\n",
            "[CV 2/5; 21/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.3s\n",
            "[CV 3/5; 21/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid..........\n",
            "[CV 3/5; 21/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 4/5; 21/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid..........\n",
            "[CV 4/5; 21/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 5/5; 21/60] START svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid..........\n",
            "[CV 5/5; 21/60] END svm__C=0.75, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 1/5; 22/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf..............\n",
            "[CV 1/5; 22/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  14.2s\n",
            "[CV 2/5; 22/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf..............\n",
            "[CV 2/5; 22/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  14.2s\n",
            "[CV 3/5; 22/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf..............\n",
            "[CV 3/5; 22/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  14.1s\n",
            "[CV 4/5; 22/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf..............\n",
            "[CV 4/5; 22/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  14.1s\n",
            "[CV 5/5; 22/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf..............\n",
            "[CV 5/5; 22/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  13.9s\n",
            "[CV 1/5; 23/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=poly.............\n",
            "[CV 1/5; 23/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=poly;, score=0.878 total time=  11.1s\n",
            "[CV 2/5; 23/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=poly.............\n",
            "[CV 2/5; 23/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=poly;, score=0.888 total time=  11.2s\n",
            "[CV 3/5; 23/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=poly.............\n",
            "[CV 3/5; 23/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  11.0s\n",
            "[CV 4/5; 23/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=poly.............\n",
            "[CV 4/5; 23/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=poly;, score=0.887 total time=  11.1s\n",
            "[CV 5/5; 23/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=poly.............\n",
            "[CV 5/5; 23/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 1/5; 24/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid..........\n",
            "[CV 1/5; 24/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 2/5; 24/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid..........\n",
            "[CV 2/5; 24/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 3/5; 24/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid..........\n",
            "[CV 3/5; 24/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 4/5; 24/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid..........\n",
            "[CV 4/5; 24/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 5/5; 24/60] START svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid..........\n",
            "[CV 5/5; 24/60] END svm__C=0.75, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 1/5; 25/60] START svm__C=1, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 1/5; 25/60] END svm__C=1, svm__gamma=0.001, svm__kernel=rbf;, score=0.865 total time=   8.8s\n",
            "[CV 2/5; 25/60] START svm__C=1, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 2/5; 25/60] END svm__C=1, svm__gamma=0.001, svm__kernel=rbf;, score=0.867 total time=   8.6s\n",
            "[CV 3/5; 25/60] START svm__C=1, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 3/5; 25/60] END svm__C=1, svm__gamma=0.001, svm__kernel=rbf;, score=0.862 total time=   8.7s\n",
            "[CV 4/5; 25/60] START svm__C=1, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 4/5; 25/60] END svm__C=1, svm__gamma=0.001, svm__kernel=rbf;, score=0.876 total time=   8.7s\n",
            "[CV 5/5; 25/60] START svm__C=1, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 5/5; 25/60] END svm__C=1, svm__gamma=0.001, svm__kernel=rbf;, score=0.859 total time=   8.7s\n",
            "[CV 1/5; 26/60] START svm__C=1, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 1/5; 26/60] END svm__C=1, svm__gamma=0.001, svm__kernel=poly;, score=0.868 total time=  10.4s\n",
            "[CV 2/5; 26/60] START svm__C=1, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 2/5; 26/60] END svm__C=1, svm__gamma=0.001, svm__kernel=poly;, score=0.877 total time=  10.5s\n",
            "[CV 3/5; 26/60] START svm__C=1, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 3/5; 26/60] END svm__C=1, svm__gamma=0.001, svm__kernel=poly;, score=0.872 total time=  10.6s\n",
            "[CV 4/5; 26/60] START svm__C=1, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 4/5; 26/60] END svm__C=1, svm__gamma=0.001, svm__kernel=poly;, score=0.880 total time=  10.4s\n",
            "[CV 5/5; 26/60] START svm__C=1, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 5/5; 26/60] END svm__C=1, svm__gamma=0.001, svm__kernel=poly;, score=0.870 total time=  10.5s\n",
            "[CV 1/5; 27/60] START svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 27/60] END svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.825 total time=   7.9s\n",
            "[CV 2/5; 27/60] START svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 27/60] END svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.827 total time=   7.8s\n",
            "[CV 3/5; 27/60] START svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 27/60] END svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.820 total time=   7.7s\n",
            "[CV 4/5; 27/60] START svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 27/60] END svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.827 total time=   7.6s\n",
            "[CV 5/5; 27/60] START svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 27/60] END svm__C=1, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.821 total time=   7.7s\n",
            "[CV 1/5; 28/60] START svm__C=1, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 1/5; 28/60] END svm__C=1, svm__gamma=0.01, svm__kernel=rbf;, score=0.296 total time=  15.0s\n",
            "[CV 2/5; 28/60] START svm__C=1, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 2/5; 28/60] END svm__C=1, svm__gamma=0.01, svm__kernel=rbf;, score=0.296 total time=  15.4s\n",
            "[CV 3/5; 28/60] START svm__C=1, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 3/5; 28/60] END svm__C=1, svm__gamma=0.01, svm__kernel=rbf;, score=0.296 total time=  15.0s\n",
            "[CV 4/5; 28/60] START svm__C=1, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 4/5; 28/60] END svm__C=1, svm__gamma=0.01, svm__kernel=rbf;, score=0.296 total time=  15.2s\n",
            "[CV 5/5; 28/60] START svm__C=1, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 5/5; 28/60] END svm__C=1, svm__gamma=0.01, svm__kernel=rbf;, score=0.295 total time=  15.2s\n",
            "[CV 1/5; 29/60] START svm__C=1, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 1/5; 29/60] END svm__C=1, svm__gamma=0.01, svm__kernel=poly;, score=0.878 total time=  11.2s\n",
            "[CV 2/5; 29/60] START svm__C=1, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 2/5; 29/60] END svm__C=1, svm__gamma=0.01, svm__kernel=poly;, score=0.888 total time=  10.9s\n",
            "[CV 3/5; 29/60] START svm__C=1, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 3/5; 29/60] END svm__C=1, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  11.1s\n",
            "[CV 4/5; 29/60] START svm__C=1, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 4/5; 29/60] END svm__C=1, svm__gamma=0.01, svm__kernel=poly;, score=0.887 total time=  11.1s\n",
            "[CV 5/5; 29/60] START svm__C=1, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 5/5; 29/60] END svm__C=1, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 1/5; 30/60] START svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 1/5; 30/60] END svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.286 total time=   7.8s\n",
            "[CV 2/5; 30/60] START svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 2/5; 30/60] END svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.273 total time=   7.7s\n",
            "[CV 3/5; 30/60] START svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 3/5; 30/60] END svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.268 total time=   7.8s\n",
            "[CV 4/5; 30/60] START svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 4/5; 30/60] END svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.269 total time=   7.6s\n",
            "[CV 5/5; 30/60] START svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 5/5; 30/60] END svm__C=1, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.260 total time=   7.8s\n",
            "[CV 1/5; 31/60] START svm__C=1, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 1/5; 31/60] END svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  15.6s\n",
            "[CV 2/5; 31/60] START svm__C=1, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 2/5; 31/60] END svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  15.5s\n",
            "[CV 3/5; 31/60] START svm__C=1, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 3/5; 31/60] END svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  15.6s\n",
            "[CV 4/5; 31/60] START svm__C=1, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 4/5; 31/60] END svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  15.4s\n",
            "[CV 5/5; 31/60] START svm__C=1, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 5/5; 31/60] END svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  15.6s\n",
            "[CV 1/5; 32/60] START svm__C=1, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 1/5; 32/60] END svm__C=1, svm__gamma=0.1, svm__kernel=poly;, score=0.878 total time=  10.9s\n",
            "[CV 2/5; 32/60] START svm__C=1, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 2/5; 32/60] END svm__C=1, svm__gamma=0.1, svm__kernel=poly;, score=0.888 total time=  11.0s\n",
            "[CV 3/5; 32/60] START svm__C=1, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 3/5; 32/60] END svm__C=1, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  11.0s\n",
            "[CV 4/5; 32/60] START svm__C=1, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 4/5; 32/60] END svm__C=1, svm__gamma=0.1, svm__kernel=poly;, score=0.887 total time=  10.9s\n",
            "[CV 5/5; 32/60] START svm__C=1, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 5/5; 32/60] END svm__C=1, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  11.0s\n",
            "[CV 1/5; 33/60] START svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 1/5; 33/60] END svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 2/5; 33/60] START svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 2/5; 33/60] END svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 3/5; 33/60] START svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 3/5; 33/60] END svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 4/5; 33/60] START svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 4/5; 33/60] END svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 5/5; 33/60] START svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 5/5; 33/60] END svm__C=1, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.3s\n",
            "[CV 1/5; 34/60] START svm__C=1, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 1/5; 34/60] END svm__C=1, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  15.4s\n",
            "[CV 2/5; 34/60] START svm__C=1, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 2/5; 34/60] END svm__C=1, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  15.5s\n",
            "[CV 3/5; 34/60] START svm__C=1, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 3/5; 34/60] END svm__C=1, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  15.4s\n",
            "[CV 4/5; 34/60] START svm__C=1, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 4/5; 34/60] END svm__C=1, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  15.7s\n",
            "[CV 5/5; 34/60] START svm__C=1, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 5/5; 34/60] END svm__C=1, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  15.5s\n",
            "[CV 1/5; 35/60] START svm__C=1, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 1/5; 35/60] END svm__C=1, svm__gamma=0.5, svm__kernel=poly;, score=0.878 total time=  11.2s\n",
            "[CV 2/5; 35/60] START svm__C=1, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 2/5; 35/60] END svm__C=1, svm__gamma=0.5, svm__kernel=poly;, score=0.888 total time=  10.9s\n",
            "[CV 3/5; 35/60] START svm__C=1, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 3/5; 35/60] END svm__C=1, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  11.1s\n",
            "[CV 4/5; 35/60] START svm__C=1, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 4/5; 35/60] END svm__C=1, svm__gamma=0.5, svm__kernel=poly;, score=0.887 total time=  11.1s\n",
            "[CV 5/5; 35/60] START svm__C=1, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 5/5; 35/60] END svm__C=1, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  10.9s\n",
            "[CV 1/5; 36/60] START svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 1/5; 36/60] END svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 2/5; 36/60] START svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 2/5; 36/60] END svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 3/5; 36/60] START svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 3/5; 36/60] END svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.0s\n",
            "[CV 4/5; 36/60] START svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 4/5; 36/60] END svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.2s\n",
            "[CV 5/5; 36/60] START svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 5/5; 36/60] END svm__C=1, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.1s\n",
            "[CV 1/5; 37/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf.............\n",
            "[CV 1/5; 37/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.883 total time=   9.7s\n",
            "[CV 2/5; 37/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf.............\n",
            "[CV 2/5; 37/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.891 total time=   9.6s\n",
            "[CV 3/5; 37/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf.............\n",
            "[CV 3/5; 37/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.880 total time=   9.7s\n",
            "[CV 4/5; 37/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf.............\n",
            "[CV 4/5; 37/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.890 total time=   9.7s\n",
            "[CV 5/5; 37/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf.............\n",
            "[CV 5/5; 37/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=rbf;, score=0.877 total time=   9.4s\n",
            "[CV 1/5; 38/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=poly............\n",
            "[CV 1/5; 38/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=poly;, score=0.880 total time=  11.2s\n",
            "[CV 2/5; 38/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=poly............\n",
            "[CV 2/5; 38/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=poly;, score=0.886 total time=  11.2s\n",
            "[CV 3/5; 38/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=poly............\n",
            "[CV 3/5; 38/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=poly;, score=0.880 total time=  10.9s\n",
            "[CV 4/5; 38/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=poly............\n",
            "[CV 4/5; 38/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=poly;, score=0.885 total time=  11.2s\n",
            "[CV 5/5; 38/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=poly............\n",
            "[CV 5/5; 38/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=poly;, score=0.879 total time=  11.1s\n",
            "[CV 1/5; 39/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid.........\n",
            "[CV 1/5; 39/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.809 total time=   7.9s\n",
            "[CV 2/5; 39/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid.........\n",
            "[CV 2/5; 39/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.814 total time=   8.4s\n",
            "[CV 3/5; 39/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid.........\n",
            "[CV 3/5; 39/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.804 total time=   8.2s\n",
            "[CV 4/5; 39/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid.........\n",
            "[CV 4/5; 39/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.811 total time=   8.1s\n",
            "[CV 5/5; 39/60] START svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid.........\n",
            "[CV 5/5; 39/60] END svm__C=2.5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.805 total time=   8.1s\n",
            "[CV 1/5; 40/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf..............\n",
            "[CV 1/5; 40/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.305 total time=  15.8s\n",
            "[CV 2/5; 40/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf..............\n",
            "[CV 2/5; 40/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.303 total time=  15.8s\n",
            "[CV 3/5; 40/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf..............\n",
            "[CV 3/5; 40/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.309 total time=  15.9s\n",
            "[CV 4/5; 40/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf..............\n",
            "[CV 4/5; 40/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.305 total time=  15.8s\n",
            "[CV 5/5; 40/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf..............\n",
            "[CV 5/5; 40/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=rbf;, score=0.303 total time=  16.0s\n",
            "[CV 1/5; 41/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=poly.............\n",
            "[CV 1/5; 41/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=poly;, score=0.878 total time=  11.0s\n",
            "[CV 2/5; 41/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=poly.............\n",
            "[CV 2/5; 41/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=poly;, score=0.888 total time=  11.0s\n",
            "[CV 3/5; 41/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=poly.............\n",
            "[CV 3/5; 41/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  11.2s\n",
            "[CV 4/5; 41/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=poly.............\n",
            "[CV 4/5; 41/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=poly;, score=0.887 total time=  11.9s\n",
            "[CV 5/5; 41/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=poly.............\n",
            "[CV 5/5; 41/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  11.5s\n",
            "[CV 1/5; 42/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid..........\n",
            "[CV 1/5; 42/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.272 total time=   7.8s\n",
            "[CV 2/5; 42/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid..........\n",
            "[CV 2/5; 42/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.258 total time=   7.4s\n",
            "[CV 3/5; 42/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid..........\n",
            "[CV 3/5; 42/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.262 total time=   8.4s\n",
            "[CV 4/5; 42/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid..........\n",
            "[CV 4/5; 42/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.248 total time=   7.5s\n",
            "[CV 5/5; 42/60] START svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid..........\n",
            "[CV 5/5; 42/60] END svm__C=2.5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.251 total time=   7.7s\n",
            "[CV 1/5; 43/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf...............\n",
            "[CV 1/5; 43/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.9s\n",
            "[CV 2/5; 43/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf...............\n",
            "[CV 2/5; 43/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.7s\n",
            "[CV 3/5; 43/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf...............\n",
            "[CV 3/5; 43/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  17.6s\n",
            "[CV 4/5; 43/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf...............\n",
            "[CV 4/5; 43/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  17.7s\n",
            "[CV 5/5; 43/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf...............\n",
            "[CV 5/5; 43/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.4s\n",
            "[CV 1/5; 44/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=poly..............\n",
            "[CV 1/5; 44/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=poly;, score=0.878 total time=  12.1s\n",
            "[CV 2/5; 44/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=poly..............\n",
            "[CV 2/5; 44/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=poly;, score=0.888 total time=  12.1s\n",
            "[CV 3/5; 44/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=poly..............\n",
            "[CV 3/5; 44/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  12.2s\n",
            "[CV 4/5; 44/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=poly..............\n",
            "[CV 4/5; 44/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=poly;, score=0.887 total time=  12.0s\n",
            "[CV 5/5; 44/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=poly..............\n",
            "[CV 5/5; 44/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  12.0s\n",
            "[CV 1/5; 45/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 45/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   9.1s\n",
            "[CV 2/5; 45/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 45/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.8s\n",
            "[CV 3/5; 45/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 45/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.4s\n",
            "[CV 4/5; 45/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 45/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 5/5; 45/60] START svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 45/60] END svm__C=2.5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.5s\n",
            "[CV 1/5; 46/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 1/5; 46/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.4s\n",
            "[CV 2/5; 46/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 2/5; 46/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  17.9s\n",
            "[CV 3/5; 46/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 3/5; 46/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  17.8s\n",
            "[CV 4/5; 46/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 4/5; 46/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  17.2s\n",
            "[CV 5/5; 46/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf...............\n",
            "[CV 5/5; 46/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  17.7s\n",
            "[CV 1/5; 47/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 1/5; 47/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=poly;, score=0.878 total time=  12.2s\n",
            "[CV 2/5; 47/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 2/5; 47/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=poly;, score=0.888 total time=  11.7s\n",
            "[CV 3/5; 47/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 3/5; 47/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  11.7s\n",
            "[CV 4/5; 47/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 4/5; 47/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=poly;, score=0.887 total time=  12.1s\n",
            "[CV 5/5; 47/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=poly..............\n",
            "[CV 5/5; 47/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  12.2s\n",
            "[CV 1/5; 48/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 48/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.7s\n",
            "[CV 2/5; 48/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 48/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 3/5; 48/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 48/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 4/5; 48/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 48/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.6s\n",
            "[CV 5/5; 48/60] START svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 48/60] END svm__C=2.5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 1/5; 49/60] START svm__C=5, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 1/5; 49/60] END svm__C=5, svm__gamma=0.001, svm__kernel=rbf;, score=0.885 total time=  11.4s\n",
            "[CV 2/5; 49/60] START svm__C=5, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 2/5; 49/60] END svm__C=5, svm__gamma=0.001, svm__kernel=rbf;, score=0.891 total time=  11.0s\n",
            "[CV 3/5; 49/60] START svm__C=5, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 3/5; 49/60] END svm__C=5, svm__gamma=0.001, svm__kernel=rbf;, score=0.884 total time=  11.0s\n",
            "[CV 4/5; 49/60] START svm__C=5, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 4/5; 49/60] END svm__C=5, svm__gamma=0.001, svm__kernel=rbf;, score=0.896 total time=  11.0s\n",
            "[CV 5/5; 49/60] START svm__C=5, svm__gamma=0.001, svm__kernel=rbf...............\n",
            "[CV 5/5; 49/60] END svm__C=5, svm__gamma=0.001, svm__kernel=rbf;, score=0.880 total time=  11.0s\n",
            "[CV 1/5; 50/60] START svm__C=5, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 1/5; 50/60] END svm__C=5, svm__gamma=0.001, svm__kernel=poly;, score=0.878 total time=  12.4s\n",
            "[CV 2/5; 50/60] START svm__C=5, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 2/5; 50/60] END svm__C=5, svm__gamma=0.001, svm__kernel=poly;, score=0.888 total time=  12.2s\n",
            "[CV 3/5; 50/60] START svm__C=5, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 3/5; 50/60] END svm__C=5, svm__gamma=0.001, svm__kernel=poly;, score=0.878 total time=  12.2s\n",
            "[CV 4/5; 50/60] START svm__C=5, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 4/5; 50/60] END svm__C=5, svm__gamma=0.001, svm__kernel=poly;, score=0.887 total time=  12.7s\n",
            "[CV 5/5; 50/60] START svm__C=5, svm__gamma=0.001, svm__kernel=poly..............\n",
            "[CV 5/5; 50/60] END svm__C=5, svm__gamma=0.001, svm__kernel=poly;, score=0.876 total time=  12.1s\n",
            "[CV 1/5; 51/60] START svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 1/5; 51/60] END svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.791 total time=   9.7s\n",
            "[CV 2/5; 51/60] START svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 2/5; 51/60] END svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.794 total time=  10.6s\n",
            "[CV 3/5; 51/60] START svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 3/5; 51/60] END svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.782 total time=   9.9s\n",
            "[CV 4/5; 51/60] START svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 4/5; 51/60] END svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.795 total time=  10.9s\n",
            "[CV 5/5; 51/60] START svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid...........\n",
            "[CV 5/5; 51/60] END svm__C=5, svm__gamma=0.001, svm__kernel=sigmoid;, score=0.777 total time=   9.5s\n",
            "[CV 1/5; 52/60] START svm__C=5, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 1/5; 52/60] END svm__C=5, svm__gamma=0.01, svm__kernel=rbf;, score=0.305 total time=  17.5s\n",
            "[CV 2/5; 52/60] START svm__C=5, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 2/5; 52/60] END svm__C=5, svm__gamma=0.01, svm__kernel=rbf;, score=0.303 total time=  17.7s\n",
            "[CV 3/5; 52/60] START svm__C=5, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 3/5; 52/60] END svm__C=5, svm__gamma=0.01, svm__kernel=rbf;, score=0.309 total time=  17.3s\n",
            "[CV 4/5; 52/60] START svm__C=5, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 4/5; 52/60] END svm__C=5, svm__gamma=0.01, svm__kernel=rbf;, score=0.305 total time=  17.4s\n",
            "[CV 5/5; 52/60] START svm__C=5, svm__gamma=0.01, svm__kernel=rbf................\n",
            "[CV 5/5; 52/60] END svm__C=5, svm__gamma=0.01, svm__kernel=rbf;, score=0.303 total time=  17.3s\n",
            "[CV 1/5; 53/60] START svm__C=5, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 1/5; 53/60] END svm__C=5, svm__gamma=0.01, svm__kernel=poly;, score=0.878 total time=  12.0s\n",
            "[CV 2/5; 53/60] START svm__C=5, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 2/5; 53/60] END svm__C=5, svm__gamma=0.01, svm__kernel=poly;, score=0.888 total time=  12.0s\n",
            "[CV 3/5; 53/60] START svm__C=5, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 3/5; 53/60] END svm__C=5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  12.1s\n",
            "[CV 4/5; 53/60] START svm__C=5, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 4/5; 53/60] END svm__C=5, svm__gamma=0.01, svm__kernel=poly;, score=0.887 total time=  12.1s\n",
            "[CV 5/5; 53/60] START svm__C=5, svm__gamma=0.01, svm__kernel=poly...............\n",
            "[CV 5/5; 53/60] END svm__C=5, svm__gamma=0.01, svm__kernel=poly;, score=0.877 total time=  12.3s\n",
            "[CV 1/5; 54/60] START svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 1/5; 54/60] END svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.272 total time=   7.4s\n",
            "[CV 2/5; 54/60] START svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 2/5; 54/60] END svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.257 total time=   7.9s\n",
            "[CV 3/5; 54/60] START svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 3/5; 54/60] END svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.265 total time=   7.5s\n",
            "[CV 4/5; 54/60] START svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 4/5; 54/60] END svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.252 total time=   7.7s\n",
            "[CV 5/5; 54/60] START svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid............\n",
            "[CV 5/5; 54/60] END svm__C=5, svm__gamma=0.01, svm__kernel=sigmoid;, score=0.254 total time=   7.5s\n",
            "[CV 1/5; 55/60] START svm__C=5, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 1/5; 55/60] END svm__C=5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.4s\n",
            "[CV 2/5; 55/60] START svm__C=5, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 2/5; 55/60] END svm__C=5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.5s\n",
            "[CV 3/5; 55/60] START svm__C=5, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 3/5; 55/60] END svm__C=5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  18.2s\n",
            "[CV 4/5; 55/60] START svm__C=5, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 4/5; 55/60] END svm__C=5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  17.6s\n",
            "[CV 5/5; 55/60] START svm__C=5, svm__gamma=0.1, svm__kernel=rbf.................\n",
            "[CV 5/5; 55/60] END svm__C=5, svm__gamma=0.1, svm__kernel=rbf;, score=0.293 total time=  17.8s\n",
            "[CV 1/5; 56/60] START svm__C=5, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 1/5; 56/60] END svm__C=5, svm__gamma=0.1, svm__kernel=poly;, score=0.878 total time=  12.0s\n",
            "[CV 2/5; 56/60] START svm__C=5, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 2/5; 56/60] END svm__C=5, svm__gamma=0.1, svm__kernel=poly;, score=0.888 total time=  12.3s\n",
            "[CV 3/5; 56/60] START svm__C=5, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 3/5; 56/60] END svm__C=5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  12.3s\n",
            "[CV 4/5; 56/60] START svm__C=5, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 4/5; 56/60] END svm__C=5, svm__gamma=0.1, svm__kernel=poly;, score=0.887 total time=  12.2s\n",
            "[CV 5/5; 56/60] START svm__C=5, svm__gamma=0.1, svm__kernel=poly................\n",
            "[CV 5/5; 56/60] END svm__C=5, svm__gamma=0.1, svm__kernel=poly;, score=0.877 total time=  12.3s\n",
            "[CV 1/5; 57/60] START svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 1/5; 57/60] END svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 2/5; 57/60] START svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 2/5; 57/60] END svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   9.2s\n",
            "[CV 3/5; 57/60] START svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 3/5; 57/60] END svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   9.1s\n",
            "[CV 4/5; 57/60] START svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 4/5; 57/60] END svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   8.9s\n",
            "[CV 5/5; 57/60] START svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid.............\n",
            "[CV 5/5; 57/60] END svm__C=5, svm__gamma=0.1, svm__kernel=sigmoid;, score=0.293 total time=   9.2s\n",
            "[CV 1/5; 58/60] START svm__C=5, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 1/5; 58/60] END svm__C=5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.5s\n",
            "[CV 2/5; 58/60] START svm__C=5, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 2/5; 58/60] END svm__C=5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.4s\n",
            "[CV 3/5; 58/60] START svm__C=5, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 3/5; 58/60] END svm__C=5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.5s\n",
            "[CV 4/5; 58/60] START svm__C=5, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 4/5; 58/60] END svm__C=5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.4s\n",
            "[CV 5/5; 58/60] START svm__C=5, svm__gamma=0.5, svm__kernel=rbf.................\n",
            "[CV 5/5; 58/60] END svm__C=5, svm__gamma=0.5, svm__kernel=rbf;, score=0.293 total time=  18.3s\n",
            "[CV 1/5; 59/60] START svm__C=5, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 1/5; 59/60] END svm__C=5, svm__gamma=0.5, svm__kernel=poly;, score=0.878 total time=  12.6s\n",
            "[CV 2/5; 59/60] START svm__C=5, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 2/5; 59/60] END svm__C=5, svm__gamma=0.5, svm__kernel=poly;, score=0.888 total time=  12.5s\n",
            "[CV 3/5; 59/60] START svm__C=5, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 3/5; 59/60] END svm__C=5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  12.5s\n",
            "[CV 4/5; 59/60] START svm__C=5, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 4/5; 59/60] END svm__C=5, svm__gamma=0.5, svm__kernel=poly;, score=0.887 total time=  12.6s\n",
            "[CV 5/5; 59/60] START svm__C=5, svm__gamma=0.5, svm__kernel=poly................\n",
            "[CV 5/5; 59/60] END svm__C=5, svm__gamma=0.5, svm__kernel=poly;, score=0.877 total time=  12.4s\n",
            "[CV 1/5; 60/60] START svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 1/5; 60/60] END svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   9.2s\n",
            "[CV 2/5; 60/60] START svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 2/5; 60/60] END svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   9.0s\n",
            "[CV 3/5; 60/60] START svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 3/5; 60/60] END svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   9.0s\n",
            "[CV 4/5; 60/60] START svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 4/5; 60/60] END svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   9.0s\n",
            "[CV 5/5; 60/60] START svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid.............\n",
            "[CV 5/5; 60/60] END svm__C=5, svm__gamma=0.5, svm__kernel=sigmoid;, score=0.293 total time=   9.2s\n",
            "Best parameters for PCA + SVM: {'svm__C': 5, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
            "Best cross-validation accuracy score: 0.89\n"
          ]
        }
      ],
      "source": [
        "#GPU PCA\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.svm import SVC\n",
        "from cuml.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "# Define the pipeline\n",
        "pipe_pca_svm = Pipeline([(\"garCollect\", GarbageCollector()),\n",
        "                         (\"svm\", SVC(random_state=42, verbose=2))])\n",
        "#svm = SVC(random_state=42, verbose=2)\n",
        "# Define the parameter grid\n",
        "param_grid_pca_svm = {\n",
        "    \"svm__C\": [0.5, 0.75, 1, 2.5, 5],\n",
        "    \"svm__gamma\": [0.001, 0.01, 0.1, 0.5],\n",
        "    \"svm__kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
        "}\n",
        "# initialize grid search\n",
        "grid_search_pca_svm = GridSearchCV(\n",
        "    estimator=pipe_pca_svm, param_grid=param_grid_pca_svm, cv=5, scoring=cuml_accuracy_scorer,\n",
        "    verbose=10, n_jobs=1\n",
        ")\n",
        "grid_search_pca_svm.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Best parameters for PCA + SVM:\", grid_search_pca_svm.best_params_)\n",
        "print(\n",
        "    \"Best cross-validation accuracy score: {:.2f}\".format(\n",
        "        grid_search_pca_svm.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['grid_search_svm.pkl']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save model\n",
        "import joblib\n",
        "joblib.dump(grid_search_pca_svm, \"grid_search_svm.pkl\")\n",
        "pd.DataFrame(grid_search_pca_svm.cv_results_).to_csv(\"grid_search_svm_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load in model if already trained\n",
        "import joblib\n",
        "grid_search_pca_svm = joblib.load(\"grid_search_svm.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for grid search svm\n",
            "val accuracy: 0.8982992016660881\n",
            "test accuracy: 0.8996179228898923\n"
          ]
        }
      ],
      "source": [
        "print(\"metrics for grid search svm\")\n",
        "y_val_pred = grid_search_pca_svm.predict(X_val)\n",
        "print(\"val accuracy:\", accuracy_score(Y_val_cupy.to_numpy(), y_val_pred))\n",
        "y_test_pred = grid_search_pca_svm.predict(X_test)\n",
        "print(\"test accuracy:\", accuracy_score(Y_test_cupy.to_numpy(), y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid search non GPU\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.svm import SVC\n",
        "from cuml.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the pipeline\n",
        "pipe_pca_svm = Pipeline([(\"svm\", SVC(random_state=42))])\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_pca_svm = {\n",
        "    \"svm__C\": [0.5, 0.75, 1, 2.5, 5],\n",
        "    \"svm__gamma\": [0.001, 0.01, 0.1, 0.5],\n",
        "    \"svm__kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
        "}\n",
        "# initialize grid search\n",
        "grid_search_pca_svm = GridSearchCV(\n",
        "    estimator=pipe_pca_svm, param_grid=param_grid_pca_svm, cv=5, scoring=\"accuracy\"\n",
        ")\n",
        "grid_search_pca_svm.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Best parameters for PCA + SVM:\", grid_search_pca_svm.best_params_)\n",
        "print(\n",
        "    \"Best cross-validation accuracy score: {:.2f}\".format(\n",
        "        grid_search_pca_svm.best_score_\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "yb8DNuNLURpq",
        "outputId": "9af1405f-5bb9-480e-c5bf-4d6948580ebe"
      },
      "outputs": [],
      "source": [
        "# Grid search LDA non GPU\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "pipe_lda_logreg = Pipeline(\n",
        "    [\n",
        "        (\"lda\", LDA()),\n",
        "        (\n",
        "            \"logreg\",\n",
        "            LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=42),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = len(np.unique(Y_train))\n",
        "max_components = min(n_features, n_classes - 1)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_lda_logreg = {\n",
        "    \"lda__n_components\": list(range(1, max_components + 1)),\n",
        "    \"logreg__C\": [0.01, 0.1, 1, 10, 100],\n",
        "}\n",
        "\n",
        "# initialize grid search\n",
        "grid_search_lda_logreg = GridSearchCV(\n",
        "    estimator=pipe_lda_logreg,\n",
        "    param_grid=param_grid_lda_logreg,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        ")\n",
        "grid_search_lda_logreg.fit(X_train, Y_train)\n",
        "\n",
        "# Printing the best parameters and the corresponding score\n",
        "print(\n",
        "    \"Best parameters for LDA + Logistic Regression (L1):\",\n",
        "    grid_search_lda_logreg.best_params_,\n",
        ")\n",
        "print(\n",
        "    \"Best cross-validation accuracy score: {:.2f}\".format(\n",
        "        grid_search_lda_logreg.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5; 1/20] START lda__n_components=1, logreg__C=0.01........................\n",
            "[CV 1/5; 1/20] END lda__n_components=1, logreg__C=0.01;, score=0.645 total time=  22.8s\n",
            "[CV 2/5; 1/20] START lda__n_components=1, logreg__C=0.01........................\n",
            "[CV 2/5; 1/20] END lda__n_components=1, logreg__C=0.01;, score=0.651 total time=  17.3s\n",
            "[CV 3/5; 1/20] START lda__n_components=1, logreg__C=0.01........................\n",
            "[CV 3/5; 1/20] END lda__n_components=1, logreg__C=0.01;, score=0.646 total time=  20.7s\n",
            "[CV 4/5; 1/20] START lda__n_components=1, logreg__C=0.01........................\n",
            "[CV 4/5; 1/20] END lda__n_components=1, logreg__C=0.01;, score=0.650 total time=  17.2s\n",
            "[CV 5/5; 1/20] START lda__n_components=1, logreg__C=0.01........................\n",
            "[CV 5/5; 1/20] END lda__n_components=1, logreg__C=0.01;, score=0.655 total time=  16.9s\n",
            "[CV 1/5; 2/20] START lda__n_components=1, logreg__C=0.1.........................\n",
            "[CV 1/5; 2/20] END lda__n_components=1, logreg__C=0.1;, score=0.649 total time=  16.6s\n",
            "[CV 2/5; 2/20] START lda__n_components=1, logreg__C=0.1.........................\n",
            "[CV 2/5; 2/20] END lda__n_components=1, logreg__C=0.1;, score=0.651 total time=  16.3s\n",
            "[CV 3/5; 2/20] START lda__n_components=1, logreg__C=0.1.........................\n",
            "[CV 3/5; 2/20] END lda__n_components=1, logreg__C=0.1;, score=0.649 total time=  17.5s\n",
            "[CV 4/5; 2/20] START lda__n_components=1, logreg__C=0.1.........................\n",
            "[CV 4/5; 2/20] END lda__n_components=1, logreg__C=0.1;, score=0.651 total time=  17.3s\n",
            "[CV 5/5; 2/20] START lda__n_components=1, logreg__C=0.1.........................\n",
            "[CV 5/5; 2/20] END lda__n_components=1, logreg__C=0.1;, score=0.657 total time=  16.1s\n",
            "[CV 1/5; 3/20] START lda__n_components=1, logreg__C=1...........................\n",
            "[CV 1/5; 3/20] END lda__n_components=1, logreg__C=1;, score=0.648 total time=  20.3s\n",
            "[CV 2/5; 3/20] START lda__n_components=1, logreg__C=1...........................\n",
            "[CV 2/5; 3/20] END lda__n_components=1, logreg__C=1;, score=0.652 total time=  17.1s\n",
            "[CV 3/5; 3/20] START lda__n_components=1, logreg__C=1...........................\n",
            "[CV 3/5; 3/20] END lda__n_components=1, logreg__C=1;, score=0.648 total time=  16.5s\n",
            "[CV 4/5; 3/20] START lda__n_components=1, logreg__C=1...........................\n",
            "[CV 4/5; 3/20] END lda__n_components=1, logreg__C=1;, score=0.652 total time=  18.5s\n",
            "[CV 5/5; 3/20] START lda__n_components=1, logreg__C=1...........................\n",
            "[CV 5/5; 3/20] END lda__n_components=1, logreg__C=1;, score=0.657 total time=  18.8s\n",
            "[CV 1/5; 4/20] START lda__n_components=1, logreg__C=10..........................\n",
            "[CV 1/5; 4/20] END lda__n_components=1, logreg__C=10;, score=0.648 total time=  16.4s\n",
            "[CV 2/5; 4/20] START lda__n_components=1, logreg__C=10..........................\n",
            "[CV 2/5; 4/20] END lda__n_components=1, logreg__C=10;, score=0.652 total time=  16.0s\n",
            "[CV 3/5; 4/20] START lda__n_components=1, logreg__C=10..........................\n",
            "[CV 3/5; 4/20] END lda__n_components=1, logreg__C=10;, score=0.648 total time=  16.0s\n",
            "[CV 4/5; 4/20] START lda__n_components=1, logreg__C=10..........................\n",
            "[CV 4/5; 4/20] END lda__n_components=1, logreg__C=10;, score=0.652 total time=  17.0s\n",
            "[CV 5/5; 4/20] START lda__n_components=1, logreg__C=10..........................\n",
            "[CV 5/5; 4/20] END lda__n_components=1, logreg__C=10;, score=0.657 total time=  16.0s\n",
            "[CV 1/5; 5/20] START lda__n_components=1, logreg__C=100.........................\n",
            "[CV 1/5; 5/20] END lda__n_components=1, logreg__C=100;, score=0.648 total time=  16.4s\n",
            "[CV 2/5; 5/20] START lda__n_components=1, logreg__C=100.........................\n",
            "[CV 2/5; 5/20] END lda__n_components=1, logreg__C=100;, score=0.652 total time=  21.2s\n",
            "[CV 3/5; 5/20] START lda__n_components=1, logreg__C=100.........................\n",
            "[CV 3/5; 5/20] END lda__n_components=1, logreg__C=100;, score=0.648 total time=  18.4s\n",
            "[CV 4/5; 5/20] START lda__n_components=1, logreg__C=100.........................\n",
            "[CV 4/5; 5/20] END lda__n_components=1, logreg__C=100;, score=0.652 total time=  20.6s\n",
            "[CV 5/5; 5/20] START lda__n_components=1, logreg__C=100.........................\n",
            "[CV 5/5; 5/20] END lda__n_components=1, logreg__C=100;, score=0.657 total time=  18.1s\n",
            "[CV 1/5; 6/20] START lda__n_components=2, logreg__C=0.01........................\n",
            "[CV 1/5; 6/20] END lda__n_components=2, logreg__C=0.01;, score=0.775 total time=  17.8s\n",
            "[CV 2/5; 6/20] START lda__n_components=2, logreg__C=0.01........................\n",
            "[CV 2/5; 6/20] END lda__n_components=2, logreg__C=0.01;, score=0.775 total time=  14.2s\n",
            "[CV 3/5; 6/20] START lda__n_components=2, logreg__C=0.01........................\n",
            "[CV 3/5; 6/20] END lda__n_components=2, logreg__C=0.01;, score=0.773 total time=  14.7s\n",
            "[CV 4/5; 6/20] START lda__n_components=2, logreg__C=0.01........................\n",
            "[CV 4/5; 6/20] END lda__n_components=2, logreg__C=0.01;, score=0.779 total time=  14.3s\n",
            "[CV 5/5; 6/20] START lda__n_components=2, logreg__C=0.01........................\n",
            "[CV 5/5; 6/20] END lda__n_components=2, logreg__C=0.01;, score=0.774 total time=  16.0s\n",
            "[CV 1/5; 7/20] START lda__n_components=2, logreg__C=0.1.........................\n",
            "[CV 1/5; 7/20] END lda__n_components=2, logreg__C=0.1;, score=0.778 total time=  14.7s\n",
            "[CV 2/5; 7/20] START lda__n_components=2, logreg__C=0.1.........................\n",
            "[CV 2/5; 7/20] END lda__n_components=2, logreg__C=0.1;, score=0.782 total time=  14.3s\n",
            "[CV 3/5; 7/20] START lda__n_components=2, logreg__C=0.1.........................\n",
            "[CV 3/5; 7/20] END lda__n_components=2, logreg__C=0.1;, score=0.777 total time=  14.6s\n",
            "[CV 4/5; 7/20] START lda__n_components=2, logreg__C=0.1.........................\n",
            "[CV 4/5; 7/20] END lda__n_components=2, logreg__C=0.1;, score=0.786 total time=  14.3s\n",
            "[CV 5/5; 7/20] START lda__n_components=2, logreg__C=0.1.........................\n",
            "[CV 5/5; 7/20] END lda__n_components=2, logreg__C=0.1;, score=0.779 total time=  14.3s\n",
            "[CV 1/5; 8/20] START lda__n_components=2, logreg__C=1...........................\n",
            "[CV 1/5; 8/20] END lda__n_components=2, logreg__C=1;, score=0.779 total time=  14.5s\n",
            "[CV 2/5; 8/20] START lda__n_components=2, logreg__C=1...........................\n",
            "[CV 2/5; 8/20] END lda__n_components=2, logreg__C=1;, score=0.782 total time=  14.5s\n",
            "[CV 3/5; 8/20] START lda__n_components=2, logreg__C=1...........................\n",
            "[CV 3/5; 8/20] END lda__n_components=2, logreg__C=1;, score=0.777 total time=  14.4s\n",
            "[CV 4/5; 8/20] START lda__n_components=2, logreg__C=1...........................\n",
            "[CV 4/5; 8/20] END lda__n_components=2, logreg__C=1;, score=0.786 total time=  15.8s\n",
            "[CV 5/5; 8/20] START lda__n_components=2, logreg__C=1...........................\n",
            "[CV 5/5; 8/20] END lda__n_components=2, logreg__C=1;, score=0.780 total time=  14.4s\n",
            "[CV 1/5; 9/20] START lda__n_components=2, logreg__C=10..........................\n",
            "[CV 1/5; 9/20] END lda__n_components=2, logreg__C=10;, score=0.779 total time=  14.2s\n",
            "[CV 2/5; 9/20] START lda__n_components=2, logreg__C=10..........................\n",
            "[CV 2/5; 9/20] END lda__n_components=2, logreg__C=10;, score=0.782 total time=  14.4s\n",
            "[CV 3/5; 9/20] START lda__n_components=2, logreg__C=10..........................\n",
            "[CV 3/5; 9/20] END lda__n_components=2, logreg__C=10;, score=0.777 total time=  14.2s\n",
            "[CV 4/5; 9/20] START lda__n_components=2, logreg__C=10..........................\n",
            "[CV 4/5; 9/20] END lda__n_components=2, logreg__C=10;, score=0.785 total time=  14.2s\n",
            "[CV 5/5; 9/20] START lda__n_components=2, logreg__C=10..........................\n",
            "[CV 5/5; 9/20] END lda__n_components=2, logreg__C=10;, score=0.780 total time=  14.4s\n",
            "[CV 1/5; 10/20] START lda__n_components=2, logreg__C=100........................\n",
            "[CV 1/5; 10/20] END lda__n_components=2, logreg__C=100;, score=0.779 total time=  15.8s\n",
            "[CV 2/5; 10/20] START lda__n_components=2, logreg__C=100........................\n",
            "[CV 2/5; 10/20] END lda__n_components=2, logreg__C=100;, score=0.782 total time=  14.2s\n",
            "[CV 3/5; 10/20] START lda__n_components=2, logreg__C=100........................\n",
            "[CV 3/5; 10/20] END lda__n_components=2, logreg__C=100;, score=0.777 total time=  14.4s\n",
            "[CV 4/5; 10/20] START lda__n_components=2, logreg__C=100........................\n",
            "[CV 4/5; 10/20] END lda__n_components=2, logreg__C=100;, score=0.786 total time=  14.4s\n",
            "[CV 5/5; 10/20] START lda__n_components=2, logreg__C=100........................\n",
            "[CV 5/5; 10/20] END lda__n_components=2, logreg__C=100;, score=0.780 total time=  14.2s\n",
            "[CV 1/5; 11/20] START lda__n_components=3, logreg__C=0.01.......................\n",
            "[CV 1/5; 11/20] END lda__n_components=3, logreg__C=0.01;, score=0.870 total time=  14.1s\n",
            "[CV 2/5; 11/20] START lda__n_components=3, logreg__C=0.01.......................\n",
            "[CV 2/5; 11/20] END lda__n_components=3, logreg__C=0.01;, score=0.874 total time=  14.3s\n",
            "[CV 3/5; 11/20] START lda__n_components=3, logreg__C=0.01.......................\n",
            "[CV 3/5; 11/20] END lda__n_components=3, logreg__C=0.01;, score=0.868 total time=  14.3s\n",
            "[CV 4/5; 11/20] START lda__n_components=3, logreg__C=0.01.......................\n",
            "[CV 4/5; 11/20] END lda__n_components=3, logreg__C=0.01;, score=0.864 total time=  17.8s\n",
            "[CV 5/5; 11/20] START lda__n_components=3, logreg__C=0.01.......................\n",
            "[CV 5/5; 11/20] END lda__n_components=3, logreg__C=0.01;, score=0.859 total time=  20.7s\n",
            "[CV 1/5; 12/20] START lda__n_components=3, logreg__C=0.1........................\n",
            "[CV 1/5; 12/20] END lda__n_components=3, logreg__C=0.1;, score=0.869 total time=  17.8s\n",
            "[CV 2/5; 12/20] START lda__n_components=3, logreg__C=0.1........................\n",
            "[CV 2/5; 12/20] END lda__n_components=3, logreg__C=0.1;, score=0.876 total time=  17.1s\n",
            "[CV 3/5; 12/20] START lda__n_components=3, logreg__C=0.1........................\n",
            "[CV 3/5; 12/20] END lda__n_components=3, logreg__C=0.1;, score=0.867 total time=  17.0s\n",
            "[CV 4/5; 12/20] START lda__n_components=3, logreg__C=0.1........................\n",
            "[CV 4/5; 12/20] END lda__n_components=3, logreg__C=0.1;, score=0.865 total time=  16.7s\n",
            "[CV 5/5; 12/20] START lda__n_components=3, logreg__C=0.1........................\n",
            "[CV 5/5; 12/20] END lda__n_components=3, logreg__C=0.1;, score=0.860 total time=  16.7s\n",
            "[CV 1/5; 13/20] START lda__n_components=3, logreg__C=1..........................\n",
            "[CV 1/5; 13/20] END lda__n_components=3, logreg__C=1;, score=0.869 total time=  16.6s\n",
            "[CV 2/5; 13/20] START lda__n_components=3, logreg__C=1..........................\n",
            "[CV 2/5; 13/20] END lda__n_components=3, logreg__C=1;, score=0.876 total time=  16.7s\n",
            "[CV 3/5; 13/20] START lda__n_components=3, logreg__C=1..........................\n",
            "[CV 3/5; 13/20] END lda__n_components=3, logreg__C=1;, score=0.867 total time=  16.8s\n",
            "[CV 4/5; 13/20] START lda__n_components=3, logreg__C=1..........................\n",
            "[CV 4/5; 13/20] END lda__n_components=3, logreg__C=1;, score=0.864 total time=  18.0s\n",
            "[CV 5/5; 13/20] START lda__n_components=3, logreg__C=1..........................\n",
            "[CV 5/5; 13/20] END lda__n_components=3, logreg__C=1;, score=0.860 total time=  16.0s\n",
            "[CV 1/5; 14/20] START lda__n_components=3, logreg__C=10.........................\n",
            "[CV 1/5; 14/20] END lda__n_components=3, logreg__C=10;, score=0.869 total time=  17.3s\n",
            "[CV 2/5; 14/20] START lda__n_components=3, logreg__C=10.........................\n",
            "[CV 2/5; 14/20] END lda__n_components=3, logreg__C=10;, score=0.876 total time=  16.6s\n",
            "[CV 3/5; 14/20] START lda__n_components=3, logreg__C=10.........................\n",
            "[CV 3/5; 14/20] END lda__n_components=3, logreg__C=10;, score=0.867 total time=  16.4s\n",
            "[CV 4/5; 14/20] START lda__n_components=3, logreg__C=10.........................\n",
            "[CV 4/5; 14/20] END lda__n_components=3, logreg__C=10;, score=0.864 total time=  16.2s\n",
            "[CV 5/5; 14/20] START lda__n_components=3, logreg__C=10.........................\n",
            "[CV 5/5; 14/20] END lda__n_components=3, logreg__C=10;, score=0.860 total time=  17.2s\n",
            "[CV 1/5; 15/20] START lda__n_components=3, logreg__C=100........................\n",
            "[CV 1/5; 15/20] END lda__n_components=3, logreg__C=100;, score=0.869 total time=  16.3s\n",
            "[CV 2/5; 15/20] START lda__n_components=3, logreg__C=100........................\n",
            "[CV 2/5; 15/20] END lda__n_components=3, logreg__C=100;, score=0.876 total time=  16.8s\n",
            "[CV 3/5; 15/20] START lda__n_components=3, logreg__C=100........................\n",
            "[CV 3/5; 15/20] END lda__n_components=3, logreg__C=100;, score=0.867 total time=  16.5s\n",
            "[CV 4/5; 15/20] START lda__n_components=3, logreg__C=100........................\n",
            "[CV 4/5; 15/20] END lda__n_components=3, logreg__C=100;, score=0.864 total time=  16.8s\n",
            "[CV 5/5; 15/20] START lda__n_components=3, logreg__C=100........................\n",
            "[CV 5/5; 15/20] END lda__n_components=3, logreg__C=100;, score=0.860 total time=  16.6s\n",
            "[CV 1/5; 16/20] START lda__n_components=4, logreg__C=0.01.......................\n",
            "[CV 1/5; 16/20] END lda__n_components=4, logreg__C=0.01;, score=0.873 total time=  17.0s\n",
            "[CV 2/5; 16/20] START lda__n_components=4, logreg__C=0.01.......................\n",
            "[CV 2/5; 16/20] END lda__n_components=4, logreg__C=0.01;, score=0.876 total time=  18.0s\n",
            "[CV 3/5; 16/20] START lda__n_components=4, logreg__C=0.01.......................\n",
            "[CV 3/5; 16/20] END lda__n_components=4, logreg__C=0.01;, score=0.870 total time=  17.2s\n",
            "[CV 4/5; 16/20] START lda__n_components=4, logreg__C=0.01.......................\n",
            "[CV 4/5; 16/20] END lda__n_components=4, logreg__C=0.01;, score=0.868 total time=  17.6s\n",
            "[CV 5/5; 16/20] START lda__n_components=4, logreg__C=0.01.......................\n",
            "[CV 5/5; 16/20] END lda__n_components=4, logreg__C=0.01;, score=0.862 total time=  16.8s\n",
            "[CV 1/5; 17/20] START lda__n_components=4, logreg__C=0.1........................\n",
            "[CV 1/5; 17/20] END lda__n_components=4, logreg__C=0.1;, score=0.873 total time=  16.3s\n",
            "[CV 2/5; 17/20] START lda__n_components=4, logreg__C=0.1........................\n",
            "[CV 2/5; 17/20] END lda__n_components=4, logreg__C=0.1;, score=0.878 total time=  16.5s\n",
            "[CV 3/5; 17/20] START lda__n_components=4, logreg__C=0.1........................\n",
            "[CV 3/5; 17/20] END lda__n_components=4, logreg__C=0.1;, score=0.869 total time=  18.9s\n",
            "[CV 4/5; 17/20] START lda__n_components=4, logreg__C=0.1........................\n",
            "[CV 4/5; 17/20] END lda__n_components=4, logreg__C=0.1;, score=0.868 total time=  16.2s\n",
            "[CV 5/5; 17/20] START lda__n_components=4, logreg__C=0.1........................\n",
            "[CV 5/5; 17/20] END lda__n_components=4, logreg__C=0.1;, score=0.862 total time=  16.3s\n",
            "[CV 1/5; 18/20] START lda__n_components=4, logreg__C=1..........................\n",
            "[CV 1/5; 18/20] END lda__n_components=4, logreg__C=1;, score=0.872 total time=  16.5s\n",
            "[CV 2/5; 18/20] START lda__n_components=4, logreg__C=1..........................\n",
            "[CV 2/5; 18/20] END lda__n_components=4, logreg__C=1;, score=0.878 total time=  17.2s\n",
            "[CV 3/5; 18/20] START lda__n_components=4, logreg__C=1..........................\n",
            "[CV 3/5; 18/20] END lda__n_components=4, logreg__C=1;, score=0.868 total time=  19.6s\n",
            "[CV 4/5; 18/20] START lda__n_components=4, logreg__C=1..........................\n",
            "[CV 4/5; 18/20] END lda__n_components=4, logreg__C=1;, score=0.868 total time=  16.6s\n",
            "[CV 5/5; 18/20] START lda__n_components=4, logreg__C=1..........................\n",
            "[CV 5/5; 18/20] END lda__n_components=4, logreg__C=1;, score=0.862 total time=  16.9s\n",
            "[CV 1/5; 19/20] START lda__n_components=4, logreg__C=10.........................\n",
            "[CV 1/5; 19/20] END lda__n_components=4, logreg__C=10;, score=0.872 total time=  16.5s\n",
            "[CV 2/5; 19/20] START lda__n_components=4, logreg__C=10.........................\n",
            "[CV 2/5; 19/20] END lda__n_components=4, logreg__C=10;, score=0.877 total time=  16.9s\n",
            "[CV 3/5; 19/20] START lda__n_components=4, logreg__C=10.........................\n",
            "[CV 3/5; 19/20] END lda__n_components=4, logreg__C=10;, score=0.868 total time=  16.8s\n",
            "[CV 4/5; 19/20] START lda__n_components=4, logreg__C=10.........................\n",
            "[CV 4/5; 19/20] END lda__n_components=4, logreg__C=10;, score=0.868 total time=  17.8s\n",
            "[CV 5/5; 19/20] START lda__n_components=4, logreg__C=10.........................\n",
            "[CV 5/5; 19/20] END lda__n_components=4, logreg__C=10;, score=0.862 total time=  16.7s\n",
            "[CV 1/5; 20/20] START lda__n_components=4, logreg__C=100........................\n",
            "[CV 1/5; 20/20] END lda__n_components=4, logreg__C=100;, score=0.872 total time=  16.7s\n",
            "[CV 2/5; 20/20] START lda__n_components=4, logreg__C=100........................\n",
            "[CV 2/5; 20/20] END lda__n_components=4, logreg__C=100;, score=0.877 total time=  16.8s\n",
            "[CV 3/5; 20/20] START lda__n_components=4, logreg__C=100........................\n",
            "[CV 3/5; 20/20] END lda__n_components=4, logreg__C=100;, score=0.868 total time=  17.3s\n",
            "[CV 4/5; 20/20] START lda__n_components=4, logreg__C=100........................\n",
            "[CV 4/5; 20/20] END lda__n_components=4, logreg__C=100;, score=0.868 total time=  16.5s\n",
            "[CV 5/5; 20/20] START lda__n_components=4, logreg__C=100........................\n",
            "[CV 5/5; 20/20] END lda__n_components=4, logreg__C=100;, score=0.862 total time=  16.4s\n",
            "Best parameters for LDA + Logistic Regression (L1): {'lda__n_components': 4, 'logreg__C': 0.1}\n",
            "Best cross-validation accuracy score: 0.87\n"
          ]
        }
      ],
      "source": [
        "# Grid search LDA non GPU\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "pipe_lda_logreg = Pipeline(\n",
        "    [\n",
        "        (\"lda\", LDA()),\n",
        "        (\n",
        "            \"logreg\",\n",
        "            LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=42),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = len(np.unique(Y_train))\n",
        "max_components = min(n_features, n_classes - 1)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_lda_logreg = {\n",
        "    \"lda__n_components\": list(range(1, max_components + 1)),\n",
        "    \"logreg__C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \n",
        "}\n",
        "\n",
        "# initialize grid search\n",
        "grid_search_lda_logreg = GridSearchCV(\n",
        "    estimator=pipe_lda_logreg,\n",
        "    param_grid=param_grid_lda_logreg,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    verbose=10\n",
        ")\n",
        "grid_search_lda_logreg.fit(X_train, Y_train)\n",
        "\n",
        "# Printing the best parameters and the corresponding score\n",
        "print(\n",
        "    \"Best parameters for LDA + Logistic Regression (L1):\",\n",
        "    grid_search_lda_logreg.best_params_,\n",
        ")\n",
        "print(\n",
        "    \"Best cross-validation accuracy score: {:.2f}\".format(\n",
        "        grid_search_lda_logreg.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['grid_search_lda_logreg.pkl']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save model\n",
        "import joblib\n",
        "joblib.dump(grid_search_lda_logreg, \"grid_search_lda_logreg.pkl\")\n",
        "pd.DataFrame(grid_search_lda_logreg.cv_results_).to_csv(\"grid_search_lda_logreg_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_lda_logreg = joblib.load(\"grid_search_lda_logreg.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for grid search lda + logreg\n",
            "val accuracy: 0.8833738285317598\n",
            "test accuracy: 0.8937130948245918\n"
          ]
        }
      ],
      "source": [
        "print(\"metrics for grid search lda + logreg\")\n",
        "y_val_pred = grid_search_lda_logreg.predict(X_val)\n",
        "print(\"val accuracy:\", accuracy_score(Y_val_cupy.to_numpy(), y_val_pred))\n",
        "y_test_pred = grid_search_lda_logreg.predict(X_test)\n",
        "print(\"test accuracy:\", accuracy_score(Y_test_cupy.to_numpy(), y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3806HRpfryZN"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efaPxAg-spmQ"
      },
      "source": [
        "pipeline resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Mk_byXrzPJ",
        "outputId": "1fc9498d-5705-402a-de22-24f080cb36c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 3)\n"
          ]
        }
      ],
      "source": [
        "# val data\n",
        "import pandas as pd\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/galaxy_zoo/test_data_reduced.csv\"\n",
        "column_names = [\"path\", \"index\", \"label\"]\n",
        "df_test = pd.read_csv(csv_file_path, names=column_names)\n",
        "df_test = df_test.iloc[1:]\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JohttW1sF6h",
        "outputId": "b3ee14f1-cd68-4272-c3de-4e1681b28afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250\n"
          ]
        }
      ],
      "source": [
        "images_list_nopreprocess_test = preprocess_resnet_nopreprocess(df_test)\n",
        "print(len(images_list_nopreprocess_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjXPUUnYsGYq",
        "outputId": "a218301d-c83d-4fa4-a0f7-a813f2ea840b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([250, 2048, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "custom_dataset_test = CustomDataset(images_list_nopreprocess_test, transform=transform)\n",
        "\n",
        "# create a data loader with batch size\n",
        "batch_size = 8\n",
        "data_loader = DataLoader(custom_dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Process images in batches\n",
        "features_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        features_test = resnet(batch.to(device))\n",
        "        features_list.append(features_test)\n",
        "\n",
        "# Concatenate features from all batches\n",
        "features_test = torch.cat(features_list, dim=0)\n",
        "\n",
        "print(features_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nLw06UVksGct",
        "outputId": "79255e22-4576-4957-94cc-c4abdcc21f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 2048)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_features_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8cd9874b-39af-48ff-bb3c-f836ce46ad13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.167135</td>\n",
              "      <td>0.381176</td>\n",
              "      <td>0.493124</td>\n",
              "      <td>0.691150</td>\n",
              "      <td>0.210178</td>\n",
              "      <td>0.155488</td>\n",
              "      <td>1.118373</td>\n",
              "      <td>1.231105</td>\n",
              "      <td>0.341808</td>\n",
              "      <td>1.088273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229235</td>\n",
              "      <td>0.524464</td>\n",
              "      <td>0.627330</td>\n",
              "      <td>0.755175</td>\n",
              "      <td>0.546383</td>\n",
              "      <td>0.090497</td>\n",
              "      <td>0.814885</td>\n",
              "      <td>0.566080</td>\n",
              "      <td>0.757683</td>\n",
              "      <td>0.222192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.289994</td>\n",
              "      <td>0.542519</td>\n",
              "      <td>0.554940</td>\n",
              "      <td>0.685290</td>\n",
              "      <td>0.220291</td>\n",
              "      <td>0.310445</td>\n",
              "      <td>0.326791</td>\n",
              "      <td>0.277052</td>\n",
              "      <td>0.338589</td>\n",
              "      <td>0.481674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.304570</td>\n",
              "      <td>0.503192</td>\n",
              "      <td>0.412349</td>\n",
              "      <td>0.664340</td>\n",
              "      <td>0.850420</td>\n",
              "      <td>0.206360</td>\n",
              "      <td>0.121112</td>\n",
              "      <td>0.089873</td>\n",
              "      <td>0.441404</td>\n",
              "      <td>0.414182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.673329</td>\n",
              "      <td>0.537883</td>\n",
              "      <td>0.790383</td>\n",
              "      <td>0.312683</td>\n",
              "      <td>0.642391</td>\n",
              "      <td>0.992894</td>\n",
              "      <td>0.107670</td>\n",
              "      <td>0.341615</td>\n",
              "      <td>0.423052</td>\n",
              "      <td>0.241216</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269985</td>\n",
              "      <td>0.226813</td>\n",
              "      <td>0.578487</td>\n",
              "      <td>0.411936</td>\n",
              "      <td>0.280815</td>\n",
              "      <td>0.339821</td>\n",
              "      <td>0.588325</td>\n",
              "      <td>0.490038</td>\n",
              "      <td>0.814451</td>\n",
              "      <td>0.271846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 2048 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cd9874b-39af-48ff-bb3c-f836ce46ad13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cd9874b-39af-48ff-bb3c-f836ce46ad13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cd9874b-39af-48ff-bb3c-f836ce46ad13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55c84363-960a-4156-a782-fba2ba7a5cd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55c84363-960a-4156-a782-fba2ba7a5cd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55c84363-960a-4156-a782-fba2ba7a5cd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0  0.167135  0.381176  0.493124  0.691150  0.210178  0.155488  1.118373   \n",
              "1  0.289994  0.542519  0.554940  0.685290  0.220291  0.310445  0.326791   \n",
              "2  0.673329  0.537883  0.790383  0.312683  0.642391  0.992894  0.107670   \n",
              "\n",
              "       7         8         9     ...      2038      2039      2040      2041  \\\n",
              "0  1.231105  0.341808  1.088273  ...  0.229235  0.524464  0.627330  0.755175   \n",
              "1  0.277052  0.338589  0.481674  ...  0.304570  0.503192  0.412349  0.664340   \n",
              "2  0.341615  0.423052  0.241216  ...  0.269985  0.226813  0.578487  0.411936   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0  0.546383  0.090497  0.814885  0.566080  0.757683  0.222192  \n",
              "1  0.850420  0.206360  0.121112  0.089873  0.441404  0.414182  \n",
              "2  0.280815  0.339821  0.588325  0.490038  0.814451  0.271846  \n",
              "\n",
              "[3 rows x 2048 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "features_test = features_test.cpu()\n",
        "# reshape it to 2000,2048\n",
        "reshaped_features_test = features_test.squeeze().numpy()\n",
        "reshaped_features_test = reshaped_features_test.reshape(\n",
        "    reshaped_features_test.shape[0], -1\n",
        ")\n",
        "# Convert to DataFrame\n",
        "df_features_test = pd.DataFrame(reshaped_features_test)\n",
        "# Display the DataFrame\n",
        "print(df_features_test.shape)\n",
        "df_features_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "7dWdrcEvsGkK",
        "outputId": "5b32b8cc-0884-4782-aa6a-ac209322bc49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_top_100_feature_pca_resnet_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-183d8a54-f991-44dc-beb4-88c59a0c823b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.151431</td>\n",
              "      <td>0.228288</td>\n",
              "      <td>-2.496917</td>\n",
              "      <td>0.343231</td>\n",
              "      <td>3.514340</td>\n",
              "      <td>1.409803</td>\n",
              "      <td>-0.565030</td>\n",
              "      <td>-1.798233</td>\n",
              "      <td>1.249460</td>\n",
              "      <td>0.562218</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.551270</td>\n",
              "      <td>0.098003</td>\n",
              "      <td>-0.211045</td>\n",
              "      <td>0.197097</td>\n",
              "      <td>0.530517</td>\n",
              "      <td>0.452060</td>\n",
              "      <td>-0.128346</td>\n",
              "      <td>0.921105</td>\n",
              "      <td>-0.440701</td>\n",
              "      <td>-0.991959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.735031</td>\n",
              "      <td>0.453660</td>\n",
              "      <td>0.953706</td>\n",
              "      <td>-1.526270</td>\n",
              "      <td>0.979842</td>\n",
              "      <td>-0.061070</td>\n",
              "      <td>-0.396701</td>\n",
              "      <td>0.109710</td>\n",
              "      <td>-4.509008</td>\n",
              "      <td>0.148838</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.249475</td>\n",
              "      <td>-0.057720</td>\n",
              "      <td>-1.127594</td>\n",
              "      <td>0.790057</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>0.182434</td>\n",
              "      <td>0.673582</td>\n",
              "      <td>-0.748875</td>\n",
              "      <td>-0.397216</td>\n",
              "      <td>0.515880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.522715</td>\n",
              "      <td>-4.190574</td>\n",
              "      <td>1.782997</td>\n",
              "      <td>0.124545</td>\n",
              "      <td>-2.565448</td>\n",
              "      <td>0.056664</td>\n",
              "      <td>-0.463572</td>\n",
              "      <td>1.728248</td>\n",
              "      <td>0.457445</td>\n",
              "      <td>-0.356052</td>\n",
              "      <td>...</td>\n",
              "      <td>0.262039</td>\n",
              "      <td>-0.430448</td>\n",
              "      <td>0.930126</td>\n",
              "      <td>-0.983385</td>\n",
              "      <td>-0.240409</td>\n",
              "      <td>-0.462527</td>\n",
              "      <td>0.067011</td>\n",
              "      <td>-0.648833</td>\n",
              "      <td>-0.254018</td>\n",
              "      <td>0.691980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-183d8a54-f991-44dc-beb4-88c59a0c823b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-183d8a54-f991-44dc-beb4-88c59a0c823b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-183d8a54-f991-44dc-beb4-88c59a0c823b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65fdcbe8-d8a1-4fb0-8344-876b4cd5ced2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65fdcbe8-d8a1-4fb0-8344-876b4cd5ced2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65fdcbe8-d8a1-4fb0-8344-876b4cd5ced2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  6.151431  0.228288 -2.496917  0.343231  3.514340  1.409803 -0.565030   \n",
              "1  4.735031  0.453660  0.953706 -1.526270  0.979842 -0.061070 -0.396701   \n",
              "2 -0.522715 -4.190574  1.782997  0.124545 -2.565448  0.056664 -0.463572   \n",
              "\n",
              "         7         8         9   ...        90        91        92        93  \\\n",
              "0 -1.798233  1.249460  0.562218  ... -0.551270  0.098003 -0.211045  0.197097   \n",
              "1  0.109710 -4.509008  0.148838  ... -0.249475 -0.057720 -1.127594  0.790057   \n",
              "2  1.728248  0.457445 -0.356052  ...  0.262039 -0.430448  0.930126 -0.983385   \n",
              "\n",
              "         94        95        96        97        98        99  \n",
              "0  0.530517  0.452060 -0.128346  0.921105 -0.440701 -0.991959  \n",
              "1  0.004476  0.182434  0.673582 -0.748875 -0.397216  0.515880  \n",
              "2 -0.240409 -0.462527  0.067011 -0.648833 -0.254018  0.691980  \n",
              "\n",
              "[3 rows x 100 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_features = df_features_test.values\n",
        "top_components = 100\n",
        "\n",
        "resnet_test_pca_feature = pick_top_feature_pca_val_test(\n",
        "    pca_train_resnet, test_features, top_components\n",
        ")\n",
        "df_top_100_feature_pca_resnet_test = pd.DataFrame(resnet_test_pca_feature)\n",
        "df_top_100_feature_pca_resnet_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEQGORW8sOql",
        "outputId": "6b494194-8304-4dd3-e409-fbabb668cffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 100)\n"
          ]
        }
      ],
      "source": [
        "Y_test_resnet = df_test[\"label\"]\n",
        "X_test_resnet = resnet_test_pca_feature\n",
        "print(X_test_resnet.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyMfJXprsn2N"
      },
      "source": [
        "pipeline1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0aIfFBYsOti",
        "outputId": "e5d3bb9c-06dd-4a01-9476-35fe4fd1aa22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:22<00:00, 11.28it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(250, 200)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"codebook.npy\", \"rb\") as f:\n",
        "    codebook = np.load(f)\n",
        "preprocessed_features_test = preprocess_1(df_test, codebook=codebook)\n",
        "preprocessed_features_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "NtpRZ56VsOwB"
      },
      "outputs": [],
      "source": [
        "Y_val_pipeline1 = df_test[\"label\"]\n",
        "max_test = np.max(preprocessed_features_test, axis=1)\n",
        "vector_representations_normalized_test = (\n",
        "    preprocessed_features_test / max_test[:, np.newaxis]\n",
        ")\n",
        "x_test_pipeline1 = vector_representations_normalized_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9npXMdOEtGri"
      },
      "source": [
        "pipeline 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6o20urPsOy_",
        "outputId": "aaf13be0-d5ad-47a6-dfb6-e780ea6a32eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 63504)\n"
          ]
        }
      ],
      "source": [
        "df_preprocessed_2_test = preprocess_2(df_test)\n",
        "df_preprocessed_2_test.columns = [\n",
        "    f\"feature_{i}\" for i in range(len(df_preprocessed_2_test.columns))\n",
        "]\n",
        "print(df_preprocessed_2_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "lPeaGHRItH9w",
        "outputId": "010183d7-ac64-4156-f64c-6d53079de3b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_top_100_feature_pca_hog_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0c0d10fc-c6da-457b-aeab-a1919126ebf7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.100329</td>\n",
              "      <td>-2.086246</td>\n",
              "      <td>0.524157</td>\n",
              "      <td>0.502610</td>\n",
              "      <td>-0.469294</td>\n",
              "      <td>-0.956327</td>\n",
              "      <td>0.909920</td>\n",
              "      <td>0.276533</td>\n",
              "      <td>-0.136504</td>\n",
              "      <td>0.319989</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.132454</td>\n",
              "      <td>0.045586</td>\n",
              "      <td>0.086657</td>\n",
              "      <td>-0.039738</td>\n",
              "      <td>-0.174275</td>\n",
              "      <td>0.088690</td>\n",
              "      <td>0.096153</td>\n",
              "      <td>0.263919</td>\n",
              "      <td>0.049217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.065967</td>\n",
              "      <td>-1.829381</td>\n",
              "      <td>1.350630</td>\n",
              "      <td>0.771141</td>\n",
              "      <td>0.262683</td>\n",
              "      <td>-0.584693</td>\n",
              "      <td>0.649360</td>\n",
              "      <td>0.497113</td>\n",
              "      <td>-0.383743</td>\n",
              "      <td>0.339792</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048076</td>\n",
              "      <td>-0.011160</td>\n",
              "      <td>-0.002185</td>\n",
              "      <td>-0.377820</td>\n",
              "      <td>0.171146</td>\n",
              "      <td>-0.106964</td>\n",
              "      <td>0.017579</td>\n",
              "      <td>0.029355</td>\n",
              "      <td>-0.038476</td>\n",
              "      <td>0.105316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.768952</td>\n",
              "      <td>-1.176423</td>\n",
              "      <td>-1.836310</td>\n",
              "      <td>-0.991434</td>\n",
              "      <td>-0.722590</td>\n",
              "      <td>1.067262</td>\n",
              "      <td>-0.330562</td>\n",
              "      <td>0.822672</td>\n",
              "      <td>-0.018184</td>\n",
              "      <td>-0.705038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065077</td>\n",
              "      <td>-0.006136</td>\n",
              "      <td>-0.022082</td>\n",
              "      <td>-0.100231</td>\n",
              "      <td>-0.062286</td>\n",
              "      <td>0.021007</td>\n",
              "      <td>0.079572</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>-0.051344</td>\n",
              "      <td>-0.176417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 200 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c0d10fc-c6da-457b-aeab-a1919126ebf7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c0d10fc-c6da-457b-aeab-a1919126ebf7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c0d10fc-c6da-457b-aeab-a1919126ebf7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41b35e85-a932-4bdc-8e50-093d681600a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41b35e85-a932-4bdc-8e50-093d681600a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41b35e85-a932-4bdc-8e50-093d681600a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.100329 -2.086246  0.524157  0.502610 -0.469294 -0.956327  0.909920   \n",
              "1  0.065967 -1.829381  1.350630  0.771141  0.262683 -0.584693  0.649360   \n",
              "2  1.768952 -1.176423 -1.836310 -0.991434 -0.722590  1.067262 -0.330562   \n",
              "\n",
              "        7         8         9    ...       190       191       192       193  \\\n",
              "0  0.276533 -0.136504  0.319989  ...  0.027726  0.132454  0.045586  0.086657   \n",
              "1  0.497113 -0.383743  0.339792  ...  0.048076 -0.011160 -0.002185 -0.377820   \n",
              "2  0.822672 -0.018184 -0.705038  ...  0.065077 -0.006136 -0.022082 -0.100231   \n",
              "\n",
              "        194       195       196       197       198       199  \n",
              "0 -0.039738 -0.174275  0.088690  0.096153  0.263919  0.049217  \n",
              "1  0.171146 -0.106964  0.017579  0.029355 -0.038476  0.105316  \n",
              "2 -0.062286  0.021007  0.079572  0.117903 -0.051344 -0.176417  \n",
              "\n",
              "[3 rows x 200 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_features = df_preprocessed_2_test.values\n",
        "top_components = 200\n",
        "\n",
        "hog_test_pca_feature = pick_top_feature_pca_val_test(\n",
        "    pca_train_hog, test_features, top_components\n",
        ")\n",
        "df_top_100_feature_pca_hog_test = pd.DataFrame(hog_test_pca_feature)\n",
        "df_top_100_feature_pca_hog_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AZ_PEdmltIXD"
      },
      "outputs": [],
      "source": [
        "df_top_100_feature_pca_hog_test_normalized = feature_normalization(\n",
        "    df_top_100_feature_pca_hog_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1YLskHd4tIZN"
      },
      "outputs": [],
      "source": [
        "X_test_hog = df_top_100_feature_pca_hog_test_normalized.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFiHmt7utnyU",
        "outputId": "63e52e76-8e64-4db6-f059-ebf173a810a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 200) (250, 200) (250, 100)\n"
          ]
        }
      ],
      "source": [
        "print(x_test_pipeline1.shape, X_test_hog.shape, resnet_test_pca_feature.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mN6KFqGtvXK",
        "outputId": "4a99f6e7-b8dd-49e7-a2ce-4b45aa6f9442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 500) (250,)\n"
          ]
        }
      ],
      "source": [
        "Y_test = df_test[\"label\"]\n",
        "\n",
        "X_test = np.hstack([x_test_pipeline1, X_test_hog, resnet_test_pca_feature])\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veE-c-UUyPkw",
        "outputId": "ed28ff23-0bde-4392-b4f2-74b876be9a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy: 0.708\n"
          ]
        }
      ],
      "source": [
        "# test accuracy\n",
        "X_test_lda = lda.transform(X_test)\n",
        "y_pred_test = classifier_l1.predict(X_test_lda)\n",
        "# evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(Y_test, y_pred_test)\n",
        "print(\"test accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "WNax4CDUuAHW",
        "outputId": "4b8de093-e7a2-43b4-c3c9-42f028458108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy: 0.712\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata set: reduced, 2000 examples, 500 for each\\n  -LDA + regression\\n    training, validation, testing: \\n  -SVM\\n    training, validation, testing: \\n    \\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test accuracy\n",
        "\n",
        "y_pred_test = svm_classifier.predict(X_test)\n",
        "# evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(Y_test, y_pred_test)\n",
        "print(\"test accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# for data set having 2000 examples\n",
        "\"\"\"\n",
        "data set: reduced, 2000 examples, 500 for each\n",
        "\t-LDA + regression\n",
        "\t\ttraining accuracy: 0.8975\n",
        "\t\tcross-val accuracy: 0.8924999999999998\n",
        "\t\ttesting accuracy: 0.708\n",
        "\t-SVM\n",
        "\t\ttraining accuracy: 0.9845\n",
        "\t\tcross-val accuracy: 0.726\n",
        "\t\ttesting accuracy: 0.712\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
